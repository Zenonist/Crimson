{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import string\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"All_1\"\n",
    "filename_KFold = '1'\n",
    "MAX_LEN = 500 #due to the max length of the token [most BERT agree 512 token] => 512 without features or labels in it\n",
    "# batch size = 16, 32\n",
    "batch_size = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime_train = pd.read_csv(f'../Data/K_Fold_Dataset/{filename_KFold}_Train.csv')\n",
    "df_crime_test = pd.read_csv(f'../Data/K_Fold_Dataset/{filename_KFold}_Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Message Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_msg(msg):\n",
    "    # ลบ text ที่อยู่ในวงเล็บ <> ทั้งหมด\n",
    "    msg = re.sub(r'<.*?>','', msg)\n",
    "    # ลบ hashtag\n",
    "    msg = re.sub(r'#','',msg)\n",
    "    # ลบ space\n",
    "    msg = re.sub(r' ','',msg)\n",
    "    # ลบ เครื่องหมายคำพูด (punctuation)\n",
    "    for c in string.punctuation:\n",
    "        msg = re.sub(r'\\{}'.format(c),'',msg)\n",
    "    # ลบ separator เช่น \\n \\t\n",
    "    msg = ' '.join(msg.split())\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract New_Data and News_Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Title</th>\n",
       "      <th>News_Intro</th>\n",
       "      <th>News_Desc</th>\n",
       "      <th>News_All</th>\n",
       "      <th>All_New_Format</th>\n",
       "      <th>Gambling</th>\n",
       "      <th>Murder</th>\n",
       "      <th>Sexual Abuse</th>\n",
       "      <th>Theft/Burglary</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Battery/Assault</th>\n",
       "      <th>Accident</th>\n",
       "      <th>Non-Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>สาวใหญ่ร้องทุกข์ ตร.นครนายก โดนหนุ่มหื่นบุกอนา...</td>\n",
       "      <td>สาวใหญ่ ร้อง ตร.นครนายก ตามจับหนุ่มหื่นบุกรุกแ...</td>\n",
       "      <td>สาวใหญ่ ร้อง ตร.นครนายก ตามจับหนุ่มหื่นบุกรุกแ...</td>\n",
       "      <td>สาวใหญ่ร้องทุกข์ ตร.นครนายก โดนหนุ่มหื่นบุกอนา...</td>\n",
       "      <td>สาวใหญ่ร้องทุกข์ตรนครนายกโดนหนุ่มหื่นบุกอนาจาร...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ร้านยาซีด!ถูกแจ้ง5ข้อหาหนัก ลอบจำหน่าย'ทรามาดอล'</td>\n",
       "      <td>ดส.บุกล่อซื้อจับ หนุ่มท่าศาลาลอบจำหน่ายยาทรามา...</td>\n",
       "      <td>เมื่อวันที่ 23 มี.ค. พ.ต.อ.จิรกฤต จารุภัทร์ ผก...</td>\n",
       "      <td>ร้านยาซีด!ถูกแจ้ง5ข้อหาหนัก ลอบจำหน่าย'ทรามาดอ...</td>\n",
       "      <td>ร้านยาซีดถูกแจ้ง5ข้อหาหนักลอบจำหน่ายทรามาดอล ด...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>อดีตกำนันกลับจากหาหมอ ขับฟอร์จูนเนอร์ชนจยย.กลา...</td>\n",
       "      <td>อดีตกำนันจากแก่งกระจาน เพชรบุรี ขับฟอร์จูนเนอร...</td>\n",
       "      <td>อดีตกำนันจากแก่งกระจาน เพชรบุรี ขับฟอร์จูนเนอร...</td>\n",
       "      <td>อดีตกำนันกลับจากหาหมอ ขับฟอร์จูนเนอร์ชนจยย.กลา...</td>\n",
       "      <td>อดีตกำนันกลับจากหาหมอขับฟอร์จูนเนอร์ชนจยยกลางแ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'จะหาได้แต่ละบาทมันเหนื่อย' สาวเซเว่นฯท้อถูกลั...</td>\n",
       "      <td>สาวเซเว่นฯ กุมขมับด้วยความเครียด จยย.ที่หามาอย...</td>\n",
       "      <td>เมื่อวันที่ 24 เม.ย. ร.ต.อ.วรุตต์ ภูมิภักดิ์ ร...</td>\n",
       "      <td>'จะหาได้แต่ละบาทมันเหนื่อย' สาวเซเว่นฯท้อถูกลั...</td>\n",
       "      <td>จะหาได้แต่ละบาทมันเหนื่อยสาวเซเว่นฯท้อถูกลักจย...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>สืบภ.6ทลายยาบ้า3.6แสนเม็ด ซุกแผ่นไม้ตบตาเจ้าหน...</td>\n",
       "      <td>ตำรวจสืบสวนภูธรภาค 6 จับกุมเอเย่นต์ยาบ้าเมืองส...</td>\n",
       "      <td>เมื่อวันที่ 28 มิ.ย. พ.ต.อ.สารนัย คงเมือง รองผ...</td>\n",
       "      <td>สืบภ.6ทลายยาบ้า3.6แสนเม็ด ซุกแผ่นไม้ตบตาเจ้าหน...</td>\n",
       "      <td>สืบภ6ทลายยาบ้า36แสนเม็ดซุกแผ่นไม้ตบตาเจ้าหน้าท...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>ใช้มาตรการพิเศษแทนเอาผิดอาญา 'ม.3'รุมสหบาทา'ม.2'</td>\n",
       "      <td>กรมพินิจฯใช้มาตรการพิเศษแทนดำเนินคดีอาญากับนัก...</td>\n",
       "      <td>เมื่อวันที่ 4 ก.พ. ที่กระทรวงยุติธรรม นายสหการ...</td>\n",
       "      <td>ใช้มาตรการพิเศษแทนเอาผิดอาญา 'ม.3'รุมสหบาทา'ม....</td>\n",
       "      <td>ใช้มาตรการพิเศษแทนเอาผิดอาญาม3รุมสหบาทาม2 กรมพ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7703</th>\n",
       "      <td>ผอ.ปัดบีบ'ด.ญ.12ขวบ'ลาออก โร่แจ้งความเอาผิดเพจดัง</td>\n",
       "      <td>ผอ.สาวโรงเรียนสังกัดเทศบาลสระบุรี ยืนยันไม่ได้...</td>\n",
       "      <td>จากกรณีโลกออนไลน์วิพากษ์วิจารณ์อย่างดุเดือด หล...</td>\n",
       "      <td>ผอ.ปัดบีบ'ด.ญ.12ขวบ'ลาออก โร่แจ้งความเอาผิดเพจ...</td>\n",
       "      <td>ผอปัดบีบดญ12ขวบลาออกโร่แจ้งความเอาผิดเพจดัง ผอ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7704</th>\n",
       "      <td>'ผู้กองจอย'ใจสู้ไม่เสียขวัญ ลั่นขออยู่ต่อช่วยเ...</td>\n",
       "      <td>รอง ผบช.ตชด. เยี่ยมปลอบขวัญให้กำลังใจตำรวจ ตชด...</td>\n",
       "      <td>เมื่อวันที่ 9 ม.ค. ที่ รพ.สิริรัตนรักษ์ ศูนย์ป...</td>\n",
       "      <td>'ผู้กองจอย'ใจสู้ไม่เสียขวัญ ลั่นขออยู่ต่อช่วยเ...</td>\n",
       "      <td>ผู้กองจอยใจสู้ไม่เสียขวัญลั่นขออยู่ต่อช่วยเหลื...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7705</th>\n",
       "      <td>\"คมนาคม\" แง้มข่าวดี เตรียมคลายล็อก บนขบวนรถไฟฟ...</td>\n",
       "      <td>\"ศักดิ์สยาม\" เผยข่าวดี หลังกรมรางฯมีข้อมูลนักร...</td>\n",
       "      <td>\"ศักดิ์สยาม\" เผยข่าวดี หลังกรมรางฯมีข้อมูลนักร...</td>\n",
       "      <td>\"คมนาคม\" แง้มข่าวดี เตรียมคลายล็อก บนขบวนรถไฟฟ...</td>\n",
       "      <td>คมนาคมแง้มข่าวดีเตรียมคลายล็อกบนขบวนรถไฟฟ้าแก้...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7706</th>\n",
       "      <td>191 จับเครือข่าย นครสวรรค์-บางบัวทอง ได้ 3 ผู้...</td>\n",
       "      <td>ตำรวจ 191 จับกุม 3 ผู้ต้องหาเครือข่ายกลุ่มผู้ค...</td>\n",
       "      <td>ตำรวจ 191 จับกุม 3 ผู้ต้องหาเครือข่ายกลุ่มผู้ค...</td>\n",
       "      <td>191 จับเครือข่าย นครสวรรค์-บางบัวทอง ได้ 3 ผู้...</td>\n",
       "      <td>191จับเครือข่ายนครสวรรค์บางบัวทองได้3ผู้ต้องหา...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7707 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             News Title  \\\n",
       "0     สาวใหญ่ร้องทุกข์ ตร.นครนายก โดนหนุ่มหื่นบุกอนา...   \n",
       "1      ร้านยาซีด!ถูกแจ้ง5ข้อหาหนัก ลอบจำหน่าย'ทรามาดอล'   \n",
       "2     อดีตกำนันกลับจากหาหมอ ขับฟอร์จูนเนอร์ชนจยย.กลา...   \n",
       "3     'จะหาได้แต่ละบาทมันเหนื่อย' สาวเซเว่นฯท้อถูกลั...   \n",
       "4     สืบภ.6ทลายยาบ้า3.6แสนเม็ด ซุกแผ่นไม้ตบตาเจ้าหน...   \n",
       "...                                                 ...   \n",
       "7702   ใช้มาตรการพิเศษแทนเอาผิดอาญา 'ม.3'รุมสหบาทา'ม.2'   \n",
       "7703  ผอ.ปัดบีบ'ด.ญ.12ขวบ'ลาออก โร่แจ้งความเอาผิดเพจดัง   \n",
       "7704  'ผู้กองจอย'ใจสู้ไม่เสียขวัญ ลั่นขออยู่ต่อช่วยเ...   \n",
       "7705  \"คมนาคม\" แง้มข่าวดี เตรียมคลายล็อก บนขบวนรถไฟฟ...   \n",
       "7706  191 จับเครือข่าย นครสวรรค์-บางบัวทอง ได้ 3 ผู้...   \n",
       "\n",
       "                                             News_Intro  \\\n",
       "0     สาวใหญ่ ร้อง ตร.นครนายก ตามจับหนุ่มหื่นบุกรุกแ...   \n",
       "1     ดส.บุกล่อซื้อจับ หนุ่มท่าศาลาลอบจำหน่ายยาทรามา...   \n",
       "2     อดีตกำนันจากแก่งกระจาน เพชรบุรี ขับฟอร์จูนเนอร...   \n",
       "3     สาวเซเว่นฯ กุมขมับด้วยความเครียด จยย.ที่หามาอย...   \n",
       "4     ตำรวจสืบสวนภูธรภาค 6 จับกุมเอเย่นต์ยาบ้าเมืองส...   \n",
       "...                                                 ...   \n",
       "7702  กรมพินิจฯใช้มาตรการพิเศษแทนดำเนินคดีอาญากับนัก...   \n",
       "7703  ผอ.สาวโรงเรียนสังกัดเทศบาลสระบุรี ยืนยันไม่ได้...   \n",
       "7704  รอง ผบช.ตชด. เยี่ยมปลอบขวัญให้กำลังใจตำรวจ ตชด...   \n",
       "7705  \"ศักดิ์สยาม\" เผยข่าวดี หลังกรมรางฯมีข้อมูลนักร...   \n",
       "7706  ตำรวจ 191 จับกุม 3 ผู้ต้องหาเครือข่ายกลุ่มผู้ค...   \n",
       "\n",
       "                                              News_Desc  \\\n",
       "0     สาวใหญ่ ร้อง ตร.นครนายก ตามจับหนุ่มหื่นบุกรุกแ...   \n",
       "1     เมื่อวันที่ 23 มี.ค. พ.ต.อ.จิรกฤต จารุภัทร์ ผก...   \n",
       "2     อดีตกำนันจากแก่งกระจาน เพชรบุรี ขับฟอร์จูนเนอร...   \n",
       "3     เมื่อวันที่ 24 เม.ย. ร.ต.อ.วรุตต์ ภูมิภักดิ์ ร...   \n",
       "4     เมื่อวันที่ 28 มิ.ย. พ.ต.อ.สารนัย คงเมือง รองผ...   \n",
       "...                                                 ...   \n",
       "7702  เมื่อวันที่ 4 ก.พ. ที่กระทรวงยุติธรรม นายสหการ...   \n",
       "7703  จากกรณีโลกออนไลน์วิพากษ์วิจารณ์อย่างดุเดือด หล...   \n",
       "7704  เมื่อวันที่ 9 ม.ค. ที่ รพ.สิริรัตนรักษ์ ศูนย์ป...   \n",
       "7705  \"ศักดิ์สยาม\" เผยข่าวดี หลังกรมรางฯมีข้อมูลนักร...   \n",
       "7706  ตำรวจ 191 จับกุม 3 ผู้ต้องหาเครือข่ายกลุ่มผู้ค...   \n",
       "\n",
       "                                               News_All  \\\n",
       "0     สาวใหญ่ร้องทุกข์ ตร.นครนายก โดนหนุ่มหื่นบุกอนา...   \n",
       "1     ร้านยาซีด!ถูกแจ้ง5ข้อหาหนัก ลอบจำหน่าย'ทรามาดอ...   \n",
       "2     อดีตกำนันกลับจากหาหมอ ขับฟอร์จูนเนอร์ชนจยย.กลา...   \n",
       "3     'จะหาได้แต่ละบาทมันเหนื่อย' สาวเซเว่นฯท้อถูกลั...   \n",
       "4     สืบภ.6ทลายยาบ้า3.6แสนเม็ด ซุกแผ่นไม้ตบตาเจ้าหน...   \n",
       "...                                                 ...   \n",
       "7702  ใช้มาตรการพิเศษแทนเอาผิดอาญา 'ม.3'รุมสหบาทา'ม....   \n",
       "7703  ผอ.ปัดบีบ'ด.ญ.12ขวบ'ลาออก โร่แจ้งความเอาผิดเพจ...   \n",
       "7704  'ผู้กองจอย'ใจสู้ไม่เสียขวัญ ลั่นขออยู่ต่อช่วยเ...   \n",
       "7705  \"คมนาคม\" แง้มข่าวดี เตรียมคลายล็อก บนขบวนรถไฟฟ...   \n",
       "7706  191 จับเครือข่าย นครสวรรค์-บางบัวทอง ได้ 3 ผู้...   \n",
       "\n",
       "                                         All_New_Format  Gambling  Murder  \\\n",
       "0     สาวใหญ่ร้องทุกข์ตรนครนายกโดนหนุ่มหื่นบุกอนาจาร...         0       0   \n",
       "1     ร้านยาซีดถูกแจ้ง5ข้อหาหนักลอบจำหน่ายทรามาดอล ด...         0       0   \n",
       "2     อดีตกำนันกลับจากหาหมอขับฟอร์จูนเนอร์ชนจยยกลางแ...         0       0   \n",
       "3     จะหาได้แต่ละบาทมันเหนื่อยสาวเซเว่นฯท้อถูกลักจย...         0       0   \n",
       "4     สืบภ6ทลายยาบ้า36แสนเม็ดซุกแผ่นไม้ตบตาเจ้าหน้าท...         0       0   \n",
       "...                                                 ...       ...     ...   \n",
       "7702  ใช้มาตรการพิเศษแทนเอาผิดอาญาม3รุมสหบาทาม2 กรมพ...         0       0   \n",
       "7703  ผอปัดบีบดญ12ขวบลาออกโร่แจ้งความเอาผิดเพจดัง ผอ...         0       0   \n",
       "7704  ผู้กองจอยใจสู้ไม่เสียขวัญลั่นขออยู่ต่อช่วยเหลื...         0       0   \n",
       "7705  คมนาคมแง้มข่าวดีเตรียมคลายล็อกบนขบวนรถไฟฟ้าแก้...         0       0   \n",
       "7706  191จับเครือข่ายนครสวรรค์บางบัวทองได้3ผู้ต้องหา...         0       0   \n",
       "\n",
       "      Sexual Abuse  Theft/Burglary  Drug  Battery/Assault  Accident  Non-Crime  \n",
       "0                1               0     0                0         0          0  \n",
       "1                0               0     1                0         0          0  \n",
       "2                0               0     0                0         1          0  \n",
       "3                0               1     0                0         0          0  \n",
       "4                0               0     1                0         0          0  \n",
       "...            ...             ...   ...              ...       ...        ...  \n",
       "7702             0               0     0                1         0          0  \n",
       "7703             1               0     0                1         0          0  \n",
       "7704             0               0     0                0         0          0  \n",
       "7705             0               0     0                0         0          1  \n",
       "7706             0               0     1                0         0          0  \n",
       "\n",
       "[7707 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crime_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_crime_train.iloc[:,3:4].values\n",
    "Y_train = df_crime_train.iloc[:,5:].values\n",
    "X_test = df_crime_test.iloc[:,3:4].values\n",
    "Y_test = df_crime_test.iloc[:,5:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['เหตุปะทะที่ปัตตานีพบคนร้ายตายเพิ่มอีก 2 รวมเป็น 7 ศพ ยึดปืนได้ 9 กระบอก ความคืบหน้าเหตุปะทะที่ปัตตานี ล่าสุด จนท.เข้าเคลียร์พื้นที่เจอศพคนร้ายอีก 2 ศพ รวมเป็น 7 ศพ ยึดปืนได้ 9 กระบอก และพบฐานปฏิบัติการ ด้าน กอ.รมน. เผยเสียใจแม้ใช้การเจรจา แต่ไร้ผลต้องยึดตามกฎหมายเมื่อเวลา 13.00 น. วันที่ 16 ส.ค.63 พลตรีปราโมทย์ พรหมอินทร์ โฆษก กอ.รมน.ภาค 4 เปิดเผยกรณีเหตุปะทะในพื้นที่ ม.2 ต.กอลำ อ.ยะรัง จ.ปัตตานี ว่า แม่ทัพภาคที่ 4 ได้กำชับเน้นย้ำการปฏิบัติของเจ้าหน้าที่ให้ใช้ความระมัดระวัง และพยายามที่จะบังคับใช้กฎหมาย เพื่อนำคนผิดม... ความคืบหน้าเหตุปะทะที่ปัตตานี ล่าสุด จนท.เข้าเคลียร์พื้นที่เจอศพคนร้ายอีก 2 ศพ รวมเป็น 7 ศพ ยึดปืนได้ 9 กระบอก และพบฐานปฏิบัติการ ด้าน กอ.รมน. เผยเสียใจแม้ใช้การเจรจา แต่ไร้ผลต้องยึดตามกฎหมายเมื่อเวลา 13.00 น. วันที่ 16 ส.ค.63 พลตรีปราโมทย์ พรหมอินทร์ โฆษก กอ.รมน.ภาค 4 เปิดเผยกรณีเหตุปะทะในพื้นที่ ม.2 ต.กอลำ อ.ยะรัง จ.ปัตตานี ว่า แม่ทัพภาคที่ 4 ได้กำชับเน้นย้ำการปฏิบัติของเจ้าหน้าที่ให้ใช้ความระมัดระวัง และพยายามที่จะบังคับใช้กฎหมาย เพื่อนำคนผิดมาลงโทษ แต่การปฏิบัติที่ผ่านมา เจ้าหน้าที่ปฏิบัติด้วยความอยากลำบาก เนื่องจากพื้นที่ที่คนร้ายหลบซ่อนตัวเป็นป่าละเมาะและทุ่งนาบริเวณกว้าง วันแรกและวันที่สองก็ได้มีการเจรจาโดยการนำผู้นำศาสนา ผู้นำท้องถิ่นมาเกลี้ยกล่อมหลายรอบ แต่คนร้ายใช้ความรุนแรงในการตอบโต้จนนำไปสู่การวิสามัญข่าวแนะนำ      โฆษก กอ.รมน.ภาค 4 กล่าวต่อว่า ล่าสุดจากการตรวจสอบพบว่าคนร้ายเสียชีวิตทั้งหมด 7 คนและตรวจยึดอาวุธได้ จำนวน 9 กระบอก ในจำนวนนี้เป็นอาวุธสงคราม 5 กระบอก ปืนพก จำนวน 4 กระบอก ในนามของ กอ.รมน.ภาค 4 ส่วนหน้าขอแสดงความเสียใจต่อครอบครัวและญาติของผู้เสียชีวิตทั้ง 7 ราย ซึ่งเป็นการเสียชีวิตที่เจ้าหน้าที่ไม่อยากให้เกิด เจ้าหน้าที่พยายามใช้ขั้นตอนจากเบาไปหาหนัก แต่คนร้ายเลือกที่จะใช้ความรุนแรงตอบโต้ โดยทางแม่ทัพขอบคุณและชื่นชมเจ้าหน้าที่ทุกฝ่ายในการปฏิบัติครั้งนี้ โดยเฉพาะทหารที่ได้รับบาดเจ็บทั้ง 3 นาย พลตรีปราโมทย์ กล่าวอีกว่า จากการตรวจฐานปฏิบัติการของคนร้ายที่ยึดมาได้ตั้งแต่วันแรกนั้น น่าจะใช้มาแล้วไม่น้อยกว่า 6 เดือน คาดว่าคนร้ายกลุ่มนี้น่าจะวางแผนเตรียมการก่อเหตุขนาดใหญ่ ตามที่เคยแจ้งเตือนมาก่อนหน้านี้ เราได้ประสานไปยังหน่วยงานที่เกี่ยวข้องเข้ามาชันสูตรพลิกศพเบื้องต้น และจะนำศพที่พบทั้งหมดไปชันสูตรอย่างละเอียดที่โรงพยาบาลต่อไป ก่อนส่งศพให้ญาตินำกลับไปประกอบพิธีทางศาสนา ส่วนวัตถุพยานทั้งหมดที่ยึดได้นั้น ทาง ผบช.ภาค 9 ได้สั่งการพนักงานสอบสวนทุกคนเก็บหลักฐานอย่างละเอียด      โฆษก กอ.รมน.ภาค 4 กล่าวด้วยว่า สิ่งที่สำคัญทางแม่ทัพเน้นย้ำให้ใช้งานมวลชนสร้างความเข้าใจต่อประชาชนที่อยู่พื้นที่เกิดเหตุ รวมทั้งสั่งการให้นายอำเภอยะรังเป็นหน่วยหลักในการสำรวจความเสียหายในการปฏิบัติในครั้งนี้ ทางเจ้าหน้าที่พร้อมจะดูแลเยียวยาผู้ได้รับความเสียหายของการปฏิบัติของเจ้าหน้าที่ สุดท้ายการปฏิบัติในครั้งนี้เจ้าหน้าที่ทุกคนใช้ความระมัดระวังกันเต็มที่ แต่คนร้ายเลือกที่จะใช้ความรุนแรงในการตอบโต้จนนำไปสู่การสูญเสีย ทั้งนี้ กอ.รมน.ภาค 4 ส่วนหน้า พร้อมเปิดโอกาสให้คนที่เห็นต่างจากรัฐที่ต้องการยุติความรุนแรงขอให้เข้ามารายงานตัวแสดงตัวต่อเจ้าหน้าที่ รับรองว่าทุกคนจะได้รับความยุติธรรมแน่นอน.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2979]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_text_arr = []\n",
    "# for i in range(len(X_train)):\n",
    "#     print(i)\n",
    "#     clean_text = clean_msg(X_train[i][0])\n",
    "#     temp_arr = []\n",
    "#     temp_arr.append(clean_text)\n",
    "#     clean_text_arr.append(temp_arr)\n",
    "# # print(clean_text_arr)\n",
    "# X_train = np.array(clean_text_arr)\n",
    "# print(X_train)\n",
    "# print(Y_train)\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into train,test,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "X_train, Y_train, X_val, Y_val = iterative_train_test_split(X_train,Y_train,test_size=0.1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = np.array([text for sub in X_train for text in sub]) \n",
    "X_test_new = np.array([text for sub in X_test for text in sub]) \n",
    "X_val_new = np.array([text for sub in X_val for text in sub]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = X_train_new.tolist()\n",
    "X_test_list = X_test_new.tolist()\n",
    "X_val_list = X_val_new.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece\n",
    "from transformers import BertTokenizer\n",
    "# cstorm125/wangchanberta-base-att-spm-uncased-finetune\n",
    "# airesearch/wangchanberta-base-att-spm-uncased\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "def preprocessing_for_bert(data):\n",
    "\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sent in data:\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            #text=text_preprocessing(sent),  \n",
    "            text=sent,\n",
    "            add_special_tokens=True,        \n",
    "            max_length=MAX_LEN,\n",
    "            truncation=True,             \n",
    "            padding='max_length',         \n",
    "            #return_tensors='pt',           \n",
    "            return_attention_mask=True      \n",
    "        )\n",
    "        \n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = np.concatenate([X_train_list, X_test_list, X_val_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1600 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "encoded_texts = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  สาวใหญ่ร้องทุกข์ ตร.นครนายก โดนหนุ่มหื่นบุกอนาจารถึงบ้าน ชี้เป็นภัยสังคม สาวใหญ่ ร้อง ตร.นครนายก ตามจับหนุ่มหื่นบุกรุกและอนาจารถึงในรีสอร์ต โชคดีหนีออกมาขอคนช่วยได้ทัน วงจรปิดจับภาพ พบผู้ก่อเหตุมีประวัติถูกจับแล้วประกันตัวออกมา วอน จนท.จัดการเพราะเป็นภัยสังคมเมื่อเวลาประมาณ 15.00 น. ของวันที่ 8 มิถุนายน 2563 ขณะ พ.ต.ต.วีรศักดิ์ ญาณวุฒิโท สว.(สอบสวน) สภ.เมืองนครนายก กำลังปฏิบัติหน้าที่อยู่ได้มีผู้เสียหายเป็นหญิงอายุ 45 ปี เข้าแจ้งความให้ช่วยติดตามผู้ก่อเหตุเป็นชายขี่รถจักรยานยนต์ ยี่ห้อฮอนด้า ซุปเปอร์คลับ สีฟ้า ทะเบียน... สาวใหญ่ ร้อง ตร.นครนายก ตามจับหนุ่มหื่นบุกรุกและอนาจารถึงในรีสอร์ต โชคดีหนีออกมาขอคนช่วยได้ทัน วงจรปิดจับภาพ พบผู้ก่อเหตุมีประวัติถูกจับแล้วประกันตัวออกมา วอน จนท.จัดการเพราะเป็นภัยสังคมเมื่อเวลาประมาณ 15.00 น. ของวันที่ 8 มิถุนายน 2563 ขณะ พ.ต.ต.วีรศักดิ์ ญาณวุฒิโท สว.(สอบสวน) สภ.เมืองนครนายก กำลังปฏิบัติหน้าที่อยู่ได้มีผู้เสียหายเป็นหญิงอายุ 45 ปี เข้าแจ้งความให้ช่วยติดตามผู้ก่อเหตุเป็นชายขี่รถจักรยานยนต์ ยี่ห้อฮอนด้า ซุปเปอร์คลับ สีฟ้า ทะเบียน 1 กค 3422 นครนายก เข้ามาจอดในรีสอร์ตแห่งหนึ่ง หมู่ 3 ต.หินตั้ง อ.เมือง จ.นครนายก ทำทีมาสอบถามราคาที่พัก และขอให้พาเดินไปดูห้องพัก ตนเองเห็นลักษณะท่าทางไม่น่าไว้ใจ เลยพาเดินไปดูห้องที่มีกล้องวงจรปิดติดอยู่ หากมีอะไรเกิดขึ้นจะได้มีหลักฐาน แต่ตนเองไม่ได้เปิดห้องให้เข้าดูเพราะไม่ไว้ใจข่าวแนะนำ      หลังจากนั้นผู้ก่อเหตุได้บอกว่าเดี๋ยวจะไปบอกเพื่อนๆ ก่อนแล้วก็ขี่รถออกไป ไม่นานก็กลับเข้ามาอีกครั้ง ครั้งนี้มานั่งอยู่บริเวณหน้าห้องต้อนรับลูกค้า&nbsp;ตนเริ่มสงสัยเลยไม่เปิดประตูออกไปคุยด้วย แต่แง้มประตูเล็กน้อยเพื่อสนทนา ผู้ก่อเหตุอ้างว่านั่งรอเพื่อนที่กำลังตามมา 3-4 คน และเดินมาหาตนเองที่ประตู บอกขอน้ำกินหน่อยตนเองบอกไม่มี หลังจากนั้นผู้ก่อเหตุได้ผลักตนเองเข้าไปในห้อง ล็อกคอ และพยายามทำมิดีมิร้าย จึงได้ต่อสู้สุดฤทธิ์ เสียงโทรศัพท์ดังขึ้นทำให้ผู้ก่อเหตุชะงัก จังหวะนั้นตนเองได้ถีบไปหนึ่งที จนสามารถดิ้นหลุดเอาตัวรอดออกมาได้ และวิ่งหนีไปขอความช่วยเหลือ&nbsp;ส่วนผู้ก่อเหตุตกใจได้วิ่งถือรองเท้าแตะและขี่รถหลบหนีไปทางเขื่อนขุนด่านปราการชล       จากการตรวจดูกล้องวงจรปิดจับภาพได้ชัดเจน จึงนำภาพไปให้หญิงสาวที่กำลังพับผ้าอยู่ในบ้านพักของตนเอง เมื่ออาทิตย์ก่อนที่เคยถูกกระทำในลักษณะเดียวกันบอกว่าเป็นคนๆ เดียวกัน ชื่อนายตี๋ โดยถูกจับแล้วประกันตัวออกมา จึงอยากให้เจ้าหน้าที่ตำรวจรีบจับตัวมาให้โดยเร็ว เพราะทราบว่า นายตี๋ เวลาเสพยาเสพติดแล้วมักจะควบคุมอารมณ์ของตัวเองไม่ได้ ถือว่าเป็นภัยต่อสังคม เกรงว่าจะไปก่อเหตุซ้ำอีก.\n",
      "\n",
      "\n",
      "Tokenized:  ['ส', '##าว', '##ใ', '##ห', '##ญ', '##่', '##ร', '##้อง', '##ท', '##ุ', '##ก', '##ข', '##์', 'ต', '##ร', '.', 'น', '##คร', '##นา', '##ย', '##ก', 'โ', '##ด', '##น', '##ห', '##น', '##ุ', '##่ม', '##ห', '##ื', '##่น', '##บ', '##ุ', '##ก', '##อน', '##า', '##จ', '##าร', '##ถ', '##ึ', '##ง', '##บ', '##้า', '##น', 'ช', '##ี', '##้', '##เป็น', '##ภ', '##ัย', '##ส', '##ัง', '##คม', 'ส', '##าว', '##ใ', '##ห', '##ญ', '##่', 'ร', '##้อง', 'ต', '##ร', '.', 'น', '##คร', '##นา', '##ย', '##ก', 'ต', '##าม', '##จ', '##ับ', '##ห', '##น', '##ุ', '##่ม', '##ห', '##ื', '##่น', '##บ', '##ุ', '##กร', '##ุ', '##ก', '##แ', '##ล', '##ะ', '##อน', '##า', '##จ', '##าร', '##ถ', '##ึ', '##ง', '##ใน', '##รี', '##ส', '##อร์', '##ต', 'โ', '##ช', '##ค', '##ดี', '##ห', '##นี', '##อ', '##อก', '##มา', '##ข', '##อ', '##ค', '##น', '##ช', '##่', '##ว', '##ย', '##ไ', '##ด้', '##ท', '##ัน', 'ว', '##ง', '##จ', '##ร', '##ป', '##ิด', '##จ', '##ับ', '##ภ', '##า', '##พ', 'พ', '##บ', '##ผ', '##ู', '##้', '##ก', '##่อ', '##เ', '##ห', '##ต', '##ุ', '##มี', '##ป', '##ร', '##ะ', '##ว', '##ั', '##ติ', '##ถ', '##ู', '##ก', '##จ', '##ับ', '##แ', '##ล้ว', '##ป', '##ร', '##ะ', '##กัน', '##ต', '##ัว', '##อ', '##อก', '##มา', 'ว', '##อน', 'จ', '##น', '##ท', '.', 'จ', '##ัด', '##การ', '##เ', '##พ', '##ร', '##า', '##ะ', '##เป็น', '##ภ', '##ัย', '##ส', '##ัง', '##คม', '##เ', '##ม', '##ื่อ', '##เ', '##ว', '##ลา', '##ป', '##ระมาณ', '15', '.', '00', 'น', '.', 'ของ', '##วันที่', '8', 'มิถุนายน', '256', '##3', 'ข', '##ณ', '##ะ', 'พ', '.', 'ต', '.', 'ต', '.', 'ว', '##ี', '##ร', '##ศ', '##ักดิ์', 'ญ', '##า', '##ณ', '##ว', '##ุ', '##ฒ', '##ิ', '##โ', '##ท', 'ส', '##ว', '.', '(', 'ส', '##อบ', '##ส', '##วน', ')', 'ส', '##ภ', '.', 'เ', '##มือง', '##น', '##คร', '##นา', '##ย', '##ก', 'ก', '##ำ', '##ล', '##ัง', '##ป', '##ฏ', '##ิ', '##บ', '##ั', '##ติ', '##ห', '##น', '##้า', '##ที่', '##อย', '##ู่', '##ไ', '##ด้', '##มี', '##ผ', '##ู', '##้', '##เ', '##ส', '##ีย', '##ห', '##าย', '##เป็น', '##ห', '##ญ', '##ิง', '##อ', '##าย', '##ุ', '45', 'ปี', 'เ', '##ข', '##้า', '##แ', '##จ', '##้', '##ง', '##ค', '##ว', '##าม', '##ใ', '##ห', '##้', '##ช', '##่', '##ว', '##ย', '##ติ', '##ด', '##ต', '##าม', '##ผ', '##ู', '##้', '##ก', '##่อ', '##เ', '##ห', '##ต', '##ุ', '##เป็น', '##ชา', '##ย', '##ข', '##ี', '##่', '##ร', '##ถ', '##จ', '##ัก', '##ร', '##ยา', '##น', '##ยน', '##ต์', 'ย', '##ี', '##่', '##ห', '##้', '##อ', '##ฮ', '##อน', '##ด้', '##า', 'ซ', '##ุ', '##ป', '##เ', '##ป', '##อร์', '##ค', '##ล', '##ับ', 'ส', '##ี', '##ฟ', '##้า', 'ท', '##ะ', '##เ', '##บ', '##ีย', '##น', '.', '.', '.', 'ส', '##าว', '##ใ', '##ห', '##ญ', '##่', 'ร', '##้อง', 'ต', '##ร', '.', 'น', '##คร', '##นา', '##ย', '##ก', 'ต', '##าม', '##จ', '##ับ', '##ห', '##น', '##ุ', '##่ม', '##ห', '##ื', '##่น', '##บ', '##ุ', '##กร', '##ุ', '##ก', '##แ', '##ล', '##ะ', '##อน', '##า', '##จ', '##าร', '##ถ', '##ึ', '##ง', '##ใน', '##รี', '##ส', '##อร์', '##ต', 'โ', '##ช', '##ค', '##ดี', '##ห', '##นี', '##อ', '##อก', '##มา', '##ข', '##อ', '##ค', '##น', '##ช', '##่', '##ว', '##ย', '##ไ', '##ด้', '##ท', '##ัน', 'ว', '##ง', '##จ', '##ร', '##ป', '##ิด', '##จ', '##ับ', '##ภ', '##า', '##พ', 'พ', '##บ', '##ผ', '##ู', '##้', '##ก', '##่อ', '##เ', '##ห', '##ต', '##ุ', '##มี', '##ป', '##ร', '##ะ', '##ว', '##ั', '##ติ', '##ถ', '##ู', '##ก', '##จ', '##ับ', '##แ', '##ล้ว', '##ป', '##ร', '##ะ', '##กัน', '##ต', '##ัว', '##อ', '##อก', '##มา', 'ว', '##อน', 'จ', '##น', '##ท', '.', 'จ', '##ัด', '##การ', '##เ', '##พ', '##ร', '##า', '##ะ', '##เป็น', '##ภ', '##ัย', '##ส', '##ัง', '##คม', '##เ', '##ม', '##ื่อ', '##เ', '##ว', '##ลา', '##ป', '##ระมาณ', '15', '.', '00', 'น', '.', 'ของ', '##วันที่', '8', 'มิถุนายน', '256', '##3', 'ข', '##ณ', '##ะ', 'พ', '.', 'ต', '.', 'ต', '.', 'ว', '##ี', '##ร', '##ศ', '##ักดิ์', 'ญ', '##า', '##ณ', '##ว', '##ุ', '##ฒ', '##ิ', '##โ', '##ท', 'ส', '##ว', '.', '(', 'ส', '##อบ', '##ส', '##วน', ')', 'ส', '##ภ', '.', 'เ', '##มือง', '##น', '##คร', '##นา', '##ย', '##ก', 'ก', '##ำ', '##ล', '##ัง', '##ป', '##ฏ', '##ิ', '##บ', '##ั', '##ติ', '##ห', '##น', '##้า', '##ที่', '##อย', '##ู่', '##ไ', '##ด้', '##มี', '##ผ', '##ู', '##้', '##เ', '##ส', '##ีย', '##ห', '##าย', '##เป็น', '##ห', '##ญ', '##ิง', '##อ', '##าย', '##ุ', '45', 'ปี', 'เ', '##ข', '##้า', '##แ', '##จ', '##้', '##ง', '##ค', '##ว', '##าม', '##ใ', '##ห', '##้', '##ช', '##่', '##ว', '##ย', '##ติ', '##ด', '##ต', '##าม', '##ผ', '##ู', '##้', '##ก', '##่อ', '##เ', '##ห', '##ต', '##ุ', '##เป็น', '##ชา', '##ย', '##ข', '##ี', '##่', '##ร', '##ถ', '##จ', '##ัก', '##ร', '##ยา', '##น', '##ยน', '##ต์', 'ย', '##ี', '##่', '##ห', '##้', '##อ', '##ฮ', '##อน', '##ด้', '##า', 'ซ', '##ุ', '##ป', '##เ', '##ป', '##อร์', '##ค', '##ล', '##ับ', 'ส', '##ี', '##ฟ', '##้า', 'ท', '##ะ', '##เ', '##บ', '##ีย', '##น', '1', 'ก', '##ค', '342', '##2', 'น', '##คร', '##นา', '##ย', '##ก', 'เ', '##ข', '##้า', '##มา', '##จ', '##อ', '##ด', '##ใน', '##รี', '##ส', '##อร์', '##ต', '##แ', '##ห', '##่ง', '##ห', '##น', '##ึ', '##่ง', 'ห', '##ม', '##ู่', '3', 'ต', '.', 'ห', '##ิน', '##ต', '##ั้ง', 'อ', '.', 'เ', '##มือง', 'จ', '.', 'น', '##คร', '##นา', '##ย', '##ก', 'ท', '##ำ', '##ท', '##ี', '##มา', '##ส', '##อบ', '##ถ', '##าม', '##ร', '##า', '##ค', '##าท', '##ี', '##่', '##พ', '##ัก', 'และ', '##ข', '##อ', '##ใ', '##ห', '##้', '##พ', '##า', '##เ', '##ด', '##ิน', '##ไ', '##ป', '##ด', '##ู', '##ห', '##้อง', '##พ', '##ัก', 'ต', '##น', '##เ', '##อง', '##เ', '##ห', '##็', '##น', '##ล', '##ัก', '##ษ', '##ณ', '##ะ', '##ท', '##่า', '##ท', '##าง', '##ไ', '##ม', '##่น', '##่า', '##ไ', '##ว', '##้', '##ใ', '##จ', 'เ', '##ล', '##ย', '##พ', '##า', '##เ', '##ด', '##ิน', '##ไ', '##ป', '##ด', '##ู', '##ห', '##้อง', '##ที่', '##มี', '##ก', '##ล', '##้อง', '##วง', '##จ', '##ร', '##ป', '##ิด', '##ติ', '##ด', '##อย', '##ู่', 'ห', '##าก', '##มี', '##อ', '##ะ', '##ไ', '##ร', '##เ', '##กิด', '##ข', '##ึ', '##้น', '##จ', '##ะ', '##ไ', '##ด้', '##มี', '##ห', '##ล', '##ัก', '##ฐ', '##าน', 'แ', '##ต', '##่', '##ต', '##น', '##เ', '##อง', '##ไ', '##ม', '##่', '##ไ', '##ด้', '##เ', '##ป', '##ิด', '##ห', '##้อง', '##ใ', '##ห', '##้', '##เ', '##ข', '##้า', '##ด', '##ู', '##เ', '##พ', '##ร', '##า', '##ะ', '##ไ', '##ม', '##่', '##ไ', '##ว', '##้', '##ใ', '##จ', '##ข', '##่า', '##ว', '##แ', '##นะ', '##น', '##ำ', 'ห', '##ล', '##ัง', '##จ', '##าก', '##นั้น', '##ผ', '##ู', '##้', '##ก', '##่อ', '##เ', '##ห', '##ต', '##ุ', '##ไ', '##ด้', '##บ', '##อก', '##ว่า', '##เ', '##ดี', '##๋', '##ย', '##ว', '##จ', '##ะ', '##ไ', '##ป', '##บ', '##อก', '##เ', '##พ', '##ื่อ', '##น', '##ๆ', 'ก', '##่อ', '##น', '##แ', '##ล้ว', '##ก', '##็', '##ข', '##ี', '##่', '##ร', '##ถ', '##อ', '##อก', '##ไ', '##ป', 'ไ', '##ม', '##่น', '##าน', '##ก', '##็', '##ก', '##ล', '##ับ', '##เ', '##ข', '##้า', '##มา', '##อ', '##ี', '##ก', '##คร', '##ั้ง', 'ครั้ง', '##นี้', '##มา', '##น', '##ั', '##่ง', '##อย', '##ู่', '##บ', '##ร', '##ิ', '##เ', '##ว', '##ณ', '##ห', '##น', '##้า', '##ห', '##้อง', '##ต', '##้', '##อน', '##ร', '##ับ', '##ล', '##ู', '##ก', '##ค', '##้า', '&', 'n', '##bs', '##p', ';', 'ต', '##น', '##เ', '##ร', '##ิ', '##่ม', '##ส', '##ง', '##ส', '##ัย', '##เ', '##ล', '##ย', '##ไ', '##ม', '##่', '##เ', '##ป', '##ิด', '##ป', '##ร', '##ะ', '##ต', '##ู', '##อ', '##อก', '##ไ', '##ป', '##ค', '##ุ', '##ย', '##ด้วย', 'แ', '##ต', '##่', '##แ', '##ง', '##้', '##ม', '##ป', '##ร', '##ะ', '##ต', '##ู', '##เ', '##ล', '##็', '##ก', '##น', '##้', '##อย', '##เ', '##พ', '##ื่อ', '##ส', '##น', '##ท', '##นา', 'ผ', '##ู', '##้', '##ก', '##่อ', '##เ', '##ห', '##ต', '##ุ', '##อ', '##้า', '##ง', '##ว่า', '##น', '##ั', '##่ง', '##ร', '##อ', '##เ', '##พ', '##ื่อ', '##น', '##ที่', '##ก', '##ำ', '##ล', '##ัง', '##ต', '##าม', '##มา', '3', '-', '4', 'คน', 'และ', '##เ', '##ด', '##ิน', '##มา', '##ห', '##า', '##ต', '##น', '##เ', '##อง', '##ที่', '##ป', '##ร', '##ะ', '##ต', '##ู', 'บ', '##อก', '##ข', '##อน', '##้', '##ำ', '##ก', '##ิน', '##ห', '##น', '##่อ', '##ย', '##ต', '##น', '##เ', '##อง', '##บ', '##อก', '##ไ', '##ม', '##่ม', '##ี', 'ห', '##ล', '##ัง', '##จ', '##าก', '##นั้น', '##ผ', '##ู', '##้', '##ก', '##่อ', '##เ', '##ห', '##ต', '##ุ', '##ไ', '##ด้', '##ผ', '##ล', '##ัก', '##ต', '##น', '##เ', '##อง', '##เ', '##ข', '##้า', '##ไ', '##ป', '##ใน', '##ห', '##้อง', 'ล', '##็', '##อก', '##ค', '##อ', 'และ', '##พ', '##ยา', '##ยา', '##ม', '##ท', '##ำ', '##ม', '##ิด', '##ี', '##ม', '##ิ', '##ร', '##้า', '##ย', 'จ', '##ึ', '##ง', '##ไ', '##ด้', '##ต', '##่อ', '##ส', '##ู', '##้', '##สุด', '##ฤ', '##ท', '##ธ', '##ิ์', 'เ', '##ส', '##ียง', '##โ', '##ท', '##ร', '##ศ', '##ั', '##พ', '##ท์', '##ด', '##ัง', '##ข', '##ึ', '##้น', '##ท', '##ำ', '##ใ', '##ห', '##้', '##ผ', '##ู', '##้', '##ก', '##่อ', '##เ', '##ห', '##ต', '##ุ', '##ช', '##ะ', '##ง', '##ัก', 'จ', '##ัง', '##ห', '##ว', '##ะ', '##นั้น', '##ต', '##น', '##เ', '##อง', '##ไ', '##ด้', '##ถ', '##ี', '##บ', '##ไ', '##ป', '##ห', '##น', '##ึ', '##่ง', '##ท', '##ี', 'จ', '##น', '##ส', '##าม', '##าร', '##ถ', '##ด', '##ิ', '##้น', '##ห', '##ล', '##ุ', '##ด', '##เ', '##อ', '##า', '##ต', '##ัว', '##ร', '##อ', '##ด', '##อ', '##อก', '##มา', '##ไ', '##ด้', 'และ', '##ว', '##ิ', '##่ง', '##ห', '##นี', '##ไ', '##ป', '##ข', '##อ', '##ค', '##ว', '##าม', '##ช', '##่', '##ว', '##ย', '##เ', '##ห', '##ล', '##ือ', '&', 'n', '##bs', '##p', ';', 'ส', '##่', '##วน', '##ผ', '##ู', '##้', '##ก', '##่อ', '##เ', '##ห', '##ต', '##ุ', '##ต', '##ก', '##ใ', '##จ', '##ไ', '##ด้', '##ว', '##ิ', '##่ง', '##ถ', '##ือ', '##ร', '##อง', '##เ', '##ท', '##้า', '##แ', '##ต', '##ะ', '##แ', '##ล', '##ะ', '##ข', '##ี', '##่', '##ร', '##ถ', '##ห', '##ล', '##บ', '##ห', '##นี', '##ไ', '##ป', '##ท', '##าง', '##เ', '##ข', '##ื่อ', '##น', '##ข', '##ุ', '##น', '##ด', '##่า', '##น', '##ป', '##ร', '##าก', '##าร', '##ช', '##ล', 'จาก', '##การ', '##ตร', '##ว', '##จ', '##ด', '##ู', '##ก', '##ล', '##้อง', '##วง', '##จ', '##ร', '##ป', '##ิด', '##จ', '##ับ', '##ภ', '##า', '##พ', '##ไ', '##ด้', '##ช', '##ัด', '##เ', '##จ', '##น', 'จ', '##ึ', '##ง', '##น', '##ำ', '##ภ', '##า', '##พ', '##ไ', '##ป', '##ใ', '##ห', '##้', '##ห', '##ญ', '##ิง', '##ส', '##าว', '##ที่', '##ก', '##ำ', '##ล', '##ัง', '##พ', '##ับ', '##ผ', '##้า', '##อย', '##ู่', '##ใน', '##บ', '##้า', '##น', '##พ', '##ัก', '##ข', '##อง', '##ต', '##น', '##เ', '##อง', 'เมื่อ', '##อ', '##าท', '##ิต', '##ย์', '##ก', '##่อ', '##น', '##ที่', '##เ', '##ค', '##ย', '##ถ', '##ู', '##ก', '##กร', '##ะ', '##ท', '##ำ', '##ใน', '##ล', '##ัก', '##ษ', '##ณ', '##ะ', '##เ', '##ดี', '##ย', '##ว', '##กัน', '##บ', '##อก', '##ว่า', '##เป็น', '##ค', '##น', '##ๆ', 'เ', '##ดี', '##ย', '##ว', '##กัน', 'ช', '##ื่อ', '##นา', '##ย', '##ต', '##ี', '##๋', 'โดย', '##ถ', '##ู', '##ก', '##จ', '##ับ', '##แ', '##ล้ว', '##ป', '##ร', '##ะ', '##กัน', '##ต', '##ัว', '##อ', '##อก', '##มา', 'จ', '##ึ', '##ง', '##อย', '##าก', '##ใ', '##ห', '##้', '##เ', '##จ', '##้า', '##ห', '##น', '##้า', '##ที่', '##ต', '##ำ', '##ร', '##ว', '##จ', '##รี', '##บ', '##จ', '##ับ', '##ต', '##ัว', '##มา', '##ใ', '##ห', '##้', '##โดย', '##เ', '##ร', '##็', '##ว', 'เ', '##พ', '##ร', '##า', '##ะ', '##ท', '##ร', '##า', '##บ', '##ว่า', 'น', '##าย', '##ต', '##ี', '##๋', 'เวลา', '##เ', '##ส', '##พ', '##ยา', '##เ', '##ส', '##พ', '##ติ', '##ด', '##แ', '##ล้ว', '##ม', '##ัก', '##จ', '##ะ', '##ค', '##ว', '##บ', '##ค', '##ุ', '##ม', '##อ', '##าร', '##ม', '##ณ์', '##ข', '##อง', '##ต', '##ัว', '##เ', '##อง', '##ไ', '##ม', '##่', '##ไ', '##ด้', 'ถ', '##ือ', '##ว่า', '##เป็น', '##ภ', '##ัย', '##ต', '##่อ', '##ส', '##ัง', '##คม', 'เ', '##กร', '##ง', '##ว่า', '##จ', '##ะ', '##ไ', '##ป', '##ก', '##่อ', '##เ', '##ห', '##ต', '##ุ', '##ซ', '##้', '##ำ', '##อ', '##ี', '##ก', '.']\n",
      "\n",
      "\n",
      "Token IDs:  [101, 1433, 65530, 111434, 111424, 55749, 31904, 22765, 75784, 37022, 53936, 18427, 80814, 26832, 1413, 22765, 119, 1417, 51752, 62904, 20503, 18427, 1452, 22123, 16000, 111424, 16000, 53936, 84307, 111424, 111429, 34523, 49097, 53936, 18427, 45629, 17344, 46856, 52780, 111419, 111428, 19197, 49097, 43102, 16000, 1402, 18260, 35933, 54699, 111422, 58077, 28767, 58264, 70280, 1433, 65530, 111434, 111424, 55749, 31904, 1427, 75784, 1413, 22765, 119, 1417, 51752, 62904, 20503, 18427, 1413, 79790, 46856, 102269, 111424, 16000, 53936, 84307, 111424, 111429, 34523, 49097, 53936, 95707, 53936, 18427, 111432, 20507, 22598, 45629, 17344, 46856, 52780, 111419, 111428, 19197, 75890, 74759, 28767, 37760, 30011, 1452, 42407, 31256, 57209, 111424, 96106, 33178, 63667, 66845, 80814, 33178, 31256, 16000, 42407, 31904, 31287, 20503, 111435, 81831, 37022, 23687, 1430, 19197, 46856, 22765, 49292, 76062, 46856, 102269, 111422, 17344, 39901, 1422, 49097, 111420, 38468, 35933, 18427, 98455, 111431, 111424, 30011, 53936, 97561, 49292, 22765, 22598, 31287, 111427, 80275, 111419, 38468, 18427, 46856, 102269, 111432, 92529, 49292, 22765, 22598, 89969, 30011, 65416, 33178, 63667, 66845, 1430, 45629, 1400, 16000, 37022, 119, 1400, 78654, 53123, 111431, 39901, 22765, 17344, 22598, 54699, 111422, 58077, 28767, 58264, 70280, 111431, 17405, 48207, 111431, 31287, 61888, 49292, 68883, 10208, 119, 11025, 1417, 119, 76523, 37840, 129, 45838, 21475, 10884, 1396, 62914, 22598, 1422, 119, 1413, 119, 1413, 119, 1430, 18260, 22765, 50443, 109841, 1405, 17344, 62914, 31287, 53936, 111418, 28220, 111433, 37022, 1433, 31287, 119, 113, 1433, 108723, 28767, 73179, 114, 1433, 111422, 119, 1450, 105710, 16000, 51752, 62904, 20503, 18427, 1395, 55593, 20507, 58264, 49292, 111416, 28220, 49097, 111427, 80275, 111424, 16000, 43102, 18203, 100145, 86063, 111435, 81831, 97561, 111420, 38468, 35933, 111431, 28767, 77654, 111424, 39376, 54699, 111424, 55749, 57558, 33178, 39376, 53936, 10827, 19141, 1450, 80814, 43102, 111432, 46856, 35933, 19197, 31256, 31287, 79790, 111434, 111424, 35933, 42407, 31904, 31287, 20503, 80275, 22123, 30011, 79790, 111420, 38468, 35933, 18427, 98455, 111431, 111424, 30011, 53936, 54699, 104034, 20503, 80814, 18260, 31904, 22765, 111419, 46856, 69365, 22765, 54633, 16000, 67390, 53008, 1426, 18260, 31904, 111424, 35933, 33178, 111426, 45629, 81831, 17344, 1403, 53936, 49292, 111431, 49292, 37760, 31256, 20507, 102269, 1433, 18260, 72245, 43102, 1415, 22598, 111431, 49097, 77654, 16000, 119, 119, 119, 1433, 65530, 111434, 111424, 55749, 31904, 1427, 75784, 1413, 22765, 119, 1417, 51752, 62904, 20503, 18427, 1413, 79790, 46856, 102269, 111424, 16000, 53936, 84307, 111424, 111429, 34523, 49097, 53936, 95707, 53936, 18427, 111432, 20507, 22598, 45629, 17344, 46856, 52780, 111419, 111428, 19197, 75890, 74759, 28767, 37760, 30011, 1452, 42407, 31256, 57209, 111424, 96106, 33178, 63667, 66845, 80814, 33178, 31256, 16000, 42407, 31904, 31287, 20503, 111435, 81831, 37022, 23687, 1430, 19197, 46856, 22765, 49292, 76062, 46856, 102269, 111422, 17344, 39901, 1422, 49097, 111420, 38468, 35933, 18427, 98455, 111431, 111424, 30011, 53936, 97561, 49292, 22765, 22598, 31287, 111427, 80275, 111419, 38468, 18427, 46856, 102269, 111432, 92529, 49292, 22765, 22598, 89969, 30011, 65416, 33178, 63667, 66845, 1430, 45629, 1400, 16000, 37022, 119, 1400, 78654, 53123, 111431, 39901, 22765, 17344, 22598, 54699, 111422, 58077, 28767, 58264, 70280, 111431, 17405, 48207, 111431, 31287, 102]\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "token_ids = list(preprocessing_for_bert([X_train_new[0]])[0].squeeze().numpy())\n",
    "print('Original: ', X_train_new[0])\n",
    "print('\\n')\n",
    "print('Tokenized: ', tokenizer.tokenize(X_train_new[0]))\n",
    "print('\\n')\n",
    "print('Token IDs: ', token_ids)\n",
    "\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train_new)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "train_labels = torch.FloatTensor(Y_train)\n",
    "val_labels = torch.FloatTensor(Y_val)\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import CamembertConfig\n",
    "\n",
    "\n",
    "def initialize_model(epochs=10):\n",
    "    bert_classifier = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased',num_labels=8)\n",
    "    bert_classifier = nn.DataParallel(bert_classifier)\n",
    "    bert_classifier.to(device)\n",
    "    \n",
    "    \n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=2e-5,    \n",
    "                      betas=(0.9, 0.98), \n",
    "                      eps=1e-6,\n",
    "                      weight_decay=0.1    \n",
    "                )\n",
    "\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0,\n",
    "                                                num_training_steps=total_steps\n",
    "                )\n",
    "    \n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.BCELoss()\n",
    "m = nn.Sigmoid()\n",
    "training_stats = list()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=10, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            outputs = model(b_input_ids, b_attn_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(m(logits), b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "\n",
    "            training_stats.append(\n",
    "                {\n",
    "                    'Epoch': epoch_i + 1,\n",
    "                    'Training_Loss': avg_train_loss,\n",
    "                    'Valid_Loss': val_loss,\n",
    "                    'Valid_Accuracy': val_accuracy,\n",
    "                    'Time_Elapsed': time_elapsed,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            torch.save(model.state_dict(), f'./Model/MBERT_{filename}_epoch{epoch_i+1}.h5')\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, b_attn_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        # Compute loss\n",
    "        #print(logits)\n",
    "        #print(b_labels)\n",
    "        loss = loss_fn(m(logits), b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        # preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        # accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        accuracy = accuracy_thresh(logits.view(-1, 8), b_labels.view(-1, 8))\n",
    "#         accuracy = accuracy_thresh(logits.view(-1, 9), b_labels.view(-1, 9))\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "def accuracy_thresh(y_pred, y_true, thresh:float=0.4, sigmoid:bool=True):\n",
    "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "    if sigmoid: \n",
    "        y_pred = y_pred.sigmoid()\n",
    "    return ((y_pred > thresh) == y_true.byte()).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/crimson/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.516090   |     -      |     -     |   8.39   \n",
      "   1    |   40    |   0.389207   |     -      |     -     |   8.04   \n",
      "   1    |   60    |   0.373991   |     -      |     -     |   8.18   \n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=4)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=4, evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, b_attn_mask)\n",
    "            logits = outputs.logits\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = all_logits.sigmoid().cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training_Loss</th>\n",
       "      <th>Valid_Loss</th>\n",
       "      <th>Valid_Accuracy</th>\n",
       "      <th>Time_Elapsed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.157732</td>\n",
       "      <td>0.168539</td>\n",
       "      <td>0.937372</td>\n",
       "      <td>122.498965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.180659</td>\n",
       "      <td>0.175106</td>\n",
       "      <td>0.934564</td>\n",
       "      <td>122.080474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.218717</td>\n",
       "      <td>0.199990</td>\n",
       "      <td>0.927509</td>\n",
       "      <td>121.907855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.334912</td>\n",
       "      <td>0.241848</td>\n",
       "      <td>0.920658</td>\n",
       "      <td>121.204345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training_Loss  Valid_Loss  Valid_Accuracy  Time_Elapsed\n",
       "Epoch                                                         \n",
       "4           0.157732    0.168539        0.937372    122.498965\n",
       "3           0.180659    0.175106        0.934564    122.080474\n",
       "2           0.218717    0.199990        0.927509    121.907855\n",
       "1           0.334912    0.241848        0.920658    121.204345"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('Epoch')\n",
    "\n",
    "# Display the table.\n",
    "df_stats.sort_values(by=['Valid_Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Run `preprocessing_for_bert` on the test set\n",
    "print('Tokenizing data...')\n",
    "test_inputs, test_masks = preprocessing_for_bert(X_test_new)\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = bert_predict(bert_classifier, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Gambling       0.00      0.00      0.00        25\n",
      "         Murder       0.90      0.84      0.87       256\n",
      "   Sexual Abuse       0.87      0.78      0.82        68\n",
      " Theft/Burglary       0.82      0.65      0.72        77\n",
      "           Drug       0.83      0.79      0.81       104\n",
      "Battery/Assault       0.65      0.53      0.58       189\n",
      "       Accident       0.73      0.68      0.71        72\n",
      "      Non-Crime       0.84      0.75      0.79       141\n",
      "\n",
      "      micro avg       0.81      0.70      0.75       932\n",
      "      macro avg       0.70      0.63      0.66       932\n",
      "   weighted avg       0.79      0.70      0.74       932\n",
      "    samples avg       0.68      0.65      0.65       932\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Gambling', 'Murder', 'Sexual Abuse', 'Theft/Burglary', 'Drug',\n",
       "       'Battery/Assault', 'Accident', 'Non-Crime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# start from 5 since we need to avoid the news_data <Topic,Intro,Desc,All>\n",
    "df_label_columns = df_crime_train.columns[5:]\n",
    "label_names = list(df_label_columns)\n",
    "\n",
    "print(classification_report(Y_test, np.round(probs), target_names=label_names, zero_division=0))\n",
    "df_label_columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
