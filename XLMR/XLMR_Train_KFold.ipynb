{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import string\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"All_1_22\"\n",
    "filename_KFold = '1'\n",
    "MAX_LEN = 500 #due to the max length of the token [most BERT agree 512 token] => 512 without features or labels in it\n",
    "# batch size = 16, 32\n",
    "batch_size = 22\n",
    "premodel_list = ['xlm-roberta-base','xlm-roberta-large']\n",
    "chosen_premodel = premodel_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime_train = pd.read_csv(f'../Data/K_Fold_Dataset/{filename_KFold}_Train.csv')\n",
    "df_crime_test = pd.read_csv(f'../Data/K_Fold_Dataset/{filename_KFold}_Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Message Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_msg(msg):\n",
    "    # ลบ text ที่อยู่ในวงเล็บ <> ทั้งหมด\n",
    "    msg = re.sub(r'<.*?>','', msg)\n",
    "    # ลบ hashtag\n",
    "    msg = re.sub(r'#','',msg)\n",
    "    # ลบ space\n",
    "    msg = re.sub(r' ','',msg)\n",
    "    # ลบ เครื่องหมายคำพูด (punctuation)\n",
    "    for c in string.punctuation:\n",
    "        msg = re.sub(r'\\{}'.format(c),'',msg)\n",
    "    # ลบ separator เช่น \\n \\t\n",
    "    msg = ' '.join(msg.split())\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract New_Data and News_Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Title</th>\n",
       "      <th>News_Intro</th>\n",
       "      <th>News_Desc</th>\n",
       "      <th>News_All</th>\n",
       "      <th>All_New_Format</th>\n",
       "      <th>Gambling</th>\n",
       "      <th>Murder</th>\n",
       "      <th>Sexual Abuse</th>\n",
       "      <th>Theft/Burglary</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Battery/Assault</th>\n",
       "      <th>Accident</th>\n",
       "      <th>Non-Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>สาวใหญ่ร้องทุกข์ ตร.นครนายก โดนหนุ่มหื่นบุกอนา...</td>\n",
       "      <td>สาวใหญ่ ร้อง ตร.นครนายก ตามจับหนุ่มหื่นบุกรุกแ...</td>\n",
       "      <td>สาวใหญ่ ร้อง ตร.นครนายก ตามจับหนุ่มหื่นบุกรุกแ...</td>\n",
       "      <td>สาวใหญ่ร้องทุกข์ ตร.นครนายก โดนหนุ่มหื่นบุกอนา...</td>\n",
       "      <td>สาวใหญ่ร้องทุกข์ตรนครนายกโดนหนุ่มหื่นบุกอนาจาร...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ร้านยาซีด!ถูกแจ้ง5ข้อหาหนัก ลอบจำหน่าย'ทรามาดอล'</td>\n",
       "      <td>ดส.บุกล่อซื้อจับ หนุ่มท่าศาลาลอบจำหน่ายยาทรามา...</td>\n",
       "      <td>เมื่อวันที่ 23 มี.ค. พ.ต.อ.จิรกฤต จารุภัทร์ ผก...</td>\n",
       "      <td>ร้านยาซีด!ถูกแจ้ง5ข้อหาหนัก ลอบจำหน่าย'ทรามาดอ...</td>\n",
       "      <td>ร้านยาซีดถูกแจ้ง5ข้อหาหนักลอบจำหน่ายทรามาดอล ด...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>อดีตกำนันกลับจากหาหมอ ขับฟอร์จูนเนอร์ชนจยย.กลา...</td>\n",
       "      <td>อดีตกำนันจากแก่งกระจาน เพชรบุรี ขับฟอร์จูนเนอร...</td>\n",
       "      <td>อดีตกำนันจากแก่งกระจาน เพชรบุรี ขับฟอร์จูนเนอร...</td>\n",
       "      <td>อดีตกำนันกลับจากหาหมอ ขับฟอร์จูนเนอร์ชนจยย.กลา...</td>\n",
       "      <td>อดีตกำนันกลับจากหาหมอขับฟอร์จูนเนอร์ชนจยยกลางแ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'จะหาได้แต่ละบาทมันเหนื่อย' สาวเซเว่นฯท้อถูกลั...</td>\n",
       "      <td>สาวเซเว่นฯ กุมขมับด้วยความเครียด จยย.ที่หามาอย...</td>\n",
       "      <td>เมื่อวันที่ 24 เม.ย. ร.ต.อ.วรุตต์ ภูมิภักดิ์ ร...</td>\n",
       "      <td>'จะหาได้แต่ละบาทมันเหนื่อย' สาวเซเว่นฯท้อถูกลั...</td>\n",
       "      <td>จะหาได้แต่ละบาทมันเหนื่อยสาวเซเว่นฯท้อถูกลักจย...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>สืบภ.6ทลายยาบ้า3.6แสนเม็ด ซุกแผ่นไม้ตบตาเจ้าหน...</td>\n",
       "      <td>ตำรวจสืบสวนภูธรภาค 6 จับกุมเอเย่นต์ยาบ้าเมืองส...</td>\n",
       "      <td>เมื่อวันที่ 28 มิ.ย. พ.ต.อ.สารนัย คงเมือง รองผ...</td>\n",
       "      <td>สืบภ.6ทลายยาบ้า3.6แสนเม็ด ซุกแผ่นไม้ตบตาเจ้าหน...</td>\n",
       "      <td>สืบภ6ทลายยาบ้า36แสนเม็ดซุกแผ่นไม้ตบตาเจ้าหน้าท...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>ใช้มาตรการพิเศษแทนเอาผิดอาญา 'ม.3'รุมสหบาทา'ม.2'</td>\n",
       "      <td>กรมพินิจฯใช้มาตรการพิเศษแทนดำเนินคดีอาญากับนัก...</td>\n",
       "      <td>เมื่อวันที่ 4 ก.พ. ที่กระทรวงยุติธรรม นายสหการ...</td>\n",
       "      <td>ใช้มาตรการพิเศษแทนเอาผิดอาญา 'ม.3'รุมสหบาทา'ม....</td>\n",
       "      <td>ใช้มาตรการพิเศษแทนเอาผิดอาญาม3รุมสหบาทาม2 กรมพ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7703</th>\n",
       "      <td>ผอ.ปัดบีบ'ด.ญ.12ขวบ'ลาออก โร่แจ้งความเอาผิดเพจดัง</td>\n",
       "      <td>ผอ.สาวโรงเรียนสังกัดเทศบาลสระบุรี ยืนยันไม่ได้...</td>\n",
       "      <td>จากกรณีโลกออนไลน์วิพากษ์วิจารณ์อย่างดุเดือด หล...</td>\n",
       "      <td>ผอ.ปัดบีบ'ด.ญ.12ขวบ'ลาออก โร่แจ้งความเอาผิดเพจ...</td>\n",
       "      <td>ผอปัดบีบดญ12ขวบลาออกโร่แจ้งความเอาผิดเพจดัง ผอ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7704</th>\n",
       "      <td>'ผู้กองจอย'ใจสู้ไม่เสียขวัญ ลั่นขออยู่ต่อช่วยเ...</td>\n",
       "      <td>รอง ผบช.ตชด. เยี่ยมปลอบขวัญให้กำลังใจตำรวจ ตชด...</td>\n",
       "      <td>เมื่อวันที่ 9 ม.ค. ที่ รพ.สิริรัตนรักษ์ ศูนย์ป...</td>\n",
       "      <td>'ผู้กองจอย'ใจสู้ไม่เสียขวัญ ลั่นขออยู่ต่อช่วยเ...</td>\n",
       "      <td>ผู้กองจอยใจสู้ไม่เสียขวัญลั่นขออยู่ต่อช่วยเหลื...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7705</th>\n",
       "      <td>\"คมนาคม\" แง้มข่าวดี เตรียมคลายล็อก บนขบวนรถไฟฟ...</td>\n",
       "      <td>\"ศักดิ์สยาม\" เผยข่าวดี หลังกรมรางฯมีข้อมูลนักร...</td>\n",
       "      <td>\"ศักดิ์สยาม\" เผยข่าวดี หลังกรมรางฯมีข้อมูลนักร...</td>\n",
       "      <td>\"คมนาคม\" แง้มข่าวดี เตรียมคลายล็อก บนขบวนรถไฟฟ...</td>\n",
       "      <td>คมนาคมแง้มข่าวดีเตรียมคลายล็อกบนขบวนรถไฟฟ้าแก้...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7706</th>\n",
       "      <td>191 จับเครือข่าย นครสวรรค์-บางบัวทอง ได้ 3 ผู้...</td>\n",
       "      <td>ตำรวจ 191 จับกุม 3 ผู้ต้องหาเครือข่ายกลุ่มผู้ค...</td>\n",
       "      <td>ตำรวจ 191 จับกุม 3 ผู้ต้องหาเครือข่ายกลุ่มผู้ค...</td>\n",
       "      <td>191 จับเครือข่าย นครสวรรค์-บางบัวทอง ได้ 3 ผู้...</td>\n",
       "      <td>191จับเครือข่ายนครสวรรค์บางบัวทองได้3ผู้ต้องหา...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7707 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             News Title  \\\n",
       "0     สาวใหญ่ร้องทุกข์ ตร.นครนายก โดนหนุ่มหื่นบุกอนา...   \n",
       "1      ร้านยาซีด!ถูกแจ้ง5ข้อหาหนัก ลอบจำหน่าย'ทรามาดอล'   \n",
       "2     อดีตกำนันกลับจากหาหมอ ขับฟอร์จูนเนอร์ชนจยย.กลา...   \n",
       "3     'จะหาได้แต่ละบาทมันเหนื่อย' สาวเซเว่นฯท้อถูกลั...   \n",
       "4     สืบภ.6ทลายยาบ้า3.6แสนเม็ด ซุกแผ่นไม้ตบตาเจ้าหน...   \n",
       "...                                                 ...   \n",
       "7702   ใช้มาตรการพิเศษแทนเอาผิดอาญา 'ม.3'รุมสหบาทา'ม.2'   \n",
       "7703  ผอ.ปัดบีบ'ด.ญ.12ขวบ'ลาออก โร่แจ้งความเอาผิดเพจดัง   \n",
       "7704  'ผู้กองจอย'ใจสู้ไม่เสียขวัญ ลั่นขออยู่ต่อช่วยเ...   \n",
       "7705  \"คมนาคม\" แง้มข่าวดี เตรียมคลายล็อก บนขบวนรถไฟฟ...   \n",
       "7706  191 จับเครือข่าย นครสวรรค์-บางบัวทอง ได้ 3 ผู้...   \n",
       "\n",
       "                                             News_Intro  \\\n",
       "0     สาวใหญ่ ร้อง ตร.นครนายก ตามจับหนุ่มหื่นบุกรุกแ...   \n",
       "1     ดส.บุกล่อซื้อจับ หนุ่มท่าศาลาลอบจำหน่ายยาทรามา...   \n",
       "2     อดีตกำนันจากแก่งกระจาน เพชรบุรี ขับฟอร์จูนเนอร...   \n",
       "3     สาวเซเว่นฯ กุมขมับด้วยความเครียด จยย.ที่หามาอย...   \n",
       "4     ตำรวจสืบสวนภูธรภาค 6 จับกุมเอเย่นต์ยาบ้าเมืองส...   \n",
       "...                                                 ...   \n",
       "7702  กรมพินิจฯใช้มาตรการพิเศษแทนดำเนินคดีอาญากับนัก...   \n",
       "7703  ผอ.สาวโรงเรียนสังกัดเทศบาลสระบุรี ยืนยันไม่ได้...   \n",
       "7704  รอง ผบช.ตชด. เยี่ยมปลอบขวัญให้กำลังใจตำรวจ ตชด...   \n",
       "7705  \"ศักดิ์สยาม\" เผยข่าวดี หลังกรมรางฯมีข้อมูลนักร...   \n",
       "7706  ตำรวจ 191 จับกุม 3 ผู้ต้องหาเครือข่ายกลุ่มผู้ค...   \n",
       "\n",
       "                                              News_Desc  \\\n",
       "0     สาวใหญ่ ร้อง ตร.นครนายก ตามจับหนุ่มหื่นบุกรุกแ...   \n",
       "1     เมื่อวันที่ 23 มี.ค. พ.ต.อ.จิรกฤต จารุภัทร์ ผก...   \n",
       "2     อดีตกำนันจากแก่งกระจาน เพชรบุรี ขับฟอร์จูนเนอร...   \n",
       "3     เมื่อวันที่ 24 เม.ย. ร.ต.อ.วรุตต์ ภูมิภักดิ์ ร...   \n",
       "4     เมื่อวันที่ 28 มิ.ย. พ.ต.อ.สารนัย คงเมือง รองผ...   \n",
       "...                                                 ...   \n",
       "7702  เมื่อวันที่ 4 ก.พ. ที่กระทรวงยุติธรรม นายสหการ...   \n",
       "7703  จากกรณีโลกออนไลน์วิพากษ์วิจารณ์อย่างดุเดือด หล...   \n",
       "7704  เมื่อวันที่ 9 ม.ค. ที่ รพ.สิริรัตนรักษ์ ศูนย์ป...   \n",
       "7705  \"ศักดิ์สยาม\" เผยข่าวดี หลังกรมรางฯมีข้อมูลนักร...   \n",
       "7706  ตำรวจ 191 จับกุม 3 ผู้ต้องหาเครือข่ายกลุ่มผู้ค...   \n",
       "\n",
       "                                               News_All  \\\n",
       "0     สาวใหญ่ร้องทุกข์ ตร.นครนายก โดนหนุ่มหื่นบุกอนา...   \n",
       "1     ร้านยาซีด!ถูกแจ้ง5ข้อหาหนัก ลอบจำหน่าย'ทรามาดอ...   \n",
       "2     อดีตกำนันกลับจากหาหมอ ขับฟอร์จูนเนอร์ชนจยย.กลา...   \n",
       "3     'จะหาได้แต่ละบาทมันเหนื่อย' สาวเซเว่นฯท้อถูกลั...   \n",
       "4     สืบภ.6ทลายยาบ้า3.6แสนเม็ด ซุกแผ่นไม้ตบตาเจ้าหน...   \n",
       "...                                                 ...   \n",
       "7702  ใช้มาตรการพิเศษแทนเอาผิดอาญา 'ม.3'รุมสหบาทา'ม....   \n",
       "7703  ผอ.ปัดบีบ'ด.ญ.12ขวบ'ลาออก โร่แจ้งความเอาผิดเพจ...   \n",
       "7704  'ผู้กองจอย'ใจสู้ไม่เสียขวัญ ลั่นขออยู่ต่อช่วยเ...   \n",
       "7705  \"คมนาคม\" แง้มข่าวดี เตรียมคลายล็อก บนขบวนรถไฟฟ...   \n",
       "7706  191 จับเครือข่าย นครสวรรค์-บางบัวทอง ได้ 3 ผู้...   \n",
       "\n",
       "                                         All_New_Format  Gambling  Murder  \\\n",
       "0     สาวใหญ่ร้องทุกข์ตรนครนายกโดนหนุ่มหื่นบุกอนาจาร...         0       0   \n",
       "1     ร้านยาซีดถูกแจ้ง5ข้อหาหนักลอบจำหน่ายทรามาดอล ด...         0       0   \n",
       "2     อดีตกำนันกลับจากหาหมอขับฟอร์จูนเนอร์ชนจยยกลางแ...         0       0   \n",
       "3     จะหาได้แต่ละบาทมันเหนื่อยสาวเซเว่นฯท้อถูกลักจย...         0       0   \n",
       "4     สืบภ6ทลายยาบ้า36แสนเม็ดซุกแผ่นไม้ตบตาเจ้าหน้าท...         0       0   \n",
       "...                                                 ...       ...     ...   \n",
       "7702  ใช้มาตรการพิเศษแทนเอาผิดอาญาม3รุมสหบาทาม2 กรมพ...         0       0   \n",
       "7703  ผอปัดบีบดญ12ขวบลาออกโร่แจ้งความเอาผิดเพจดัง ผอ...         0       0   \n",
       "7704  ผู้กองจอยใจสู้ไม่เสียขวัญลั่นขออยู่ต่อช่วยเหลื...         0       0   \n",
       "7705  คมนาคมแง้มข่าวดีเตรียมคลายล็อกบนขบวนรถไฟฟ้าแก้...         0       0   \n",
       "7706  191จับเครือข่ายนครสวรรค์บางบัวทองได้3ผู้ต้องหา...         0       0   \n",
       "\n",
       "      Sexual Abuse  Theft/Burglary  Drug  Battery/Assault  Accident  Non-Crime  \n",
       "0                1               0     0                0         0          0  \n",
       "1                0               0     1                0         0          0  \n",
       "2                0               0     0                0         1          0  \n",
       "3                0               1     0                0         0          0  \n",
       "4                0               0     1                0         0          0  \n",
       "...            ...             ...   ...              ...       ...        ...  \n",
       "7702             0               0     0                1         0          0  \n",
       "7703             1               0     0                1         0          0  \n",
       "7704             0               0     0                0         0          0  \n",
       "7705             0               0     0                0         0          1  \n",
       "7706             0               0     1                0         0          0  \n",
       "\n",
       "[7707 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crime_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_crime_train.iloc[:,3:4].values\n",
    "Y_train = df_crime_train.iloc[:,5:].values\n",
    "X_test = df_crime_test.iloc[:,3:4].values\n",
    "Y_test = df_crime_test.iloc[:,5:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['เหตุปะทะที่ปัตตานีพบคนร้ายตายเพิ่มอีก 2 รวมเป็น 7 ศพ ยึดปืนได้ 9 กระบอก ความคืบหน้าเหตุปะทะที่ปัตตานี ล่าสุด จนท.เข้าเคลียร์พื้นที่เจอศพคนร้ายอีก 2 ศพ รวมเป็น 7 ศพ ยึดปืนได้ 9 กระบอก และพบฐานปฏิบัติการ ด้าน กอ.รมน. เผยเสียใจแม้ใช้การเจรจา แต่ไร้ผลต้องยึดตามกฎหมายเมื่อเวลา 13.00 น. วันที่ 16 ส.ค.63 พลตรีปราโมทย์ พรหมอินทร์ โฆษก กอ.รมน.ภาค 4 เปิดเผยกรณีเหตุปะทะในพื้นที่ ม.2 ต.กอลำ อ.ยะรัง จ.ปัตตานี ว่า แม่ทัพภาคที่ 4 ได้กำชับเน้นย้ำการปฏิบัติของเจ้าหน้าที่ให้ใช้ความระมัดระวัง และพยายามที่จะบังคับใช้กฎหมาย เพื่อนำคนผิดม... ความคืบหน้าเหตุปะทะที่ปัตตานี ล่าสุด จนท.เข้าเคลียร์พื้นที่เจอศพคนร้ายอีก 2 ศพ รวมเป็น 7 ศพ ยึดปืนได้ 9 กระบอก และพบฐานปฏิบัติการ ด้าน กอ.รมน. เผยเสียใจแม้ใช้การเจรจา แต่ไร้ผลต้องยึดตามกฎหมายเมื่อเวลา 13.00 น. วันที่ 16 ส.ค.63 พลตรีปราโมทย์ พรหมอินทร์ โฆษก กอ.รมน.ภาค 4 เปิดเผยกรณีเหตุปะทะในพื้นที่ ม.2 ต.กอลำ อ.ยะรัง จ.ปัตตานี ว่า แม่ทัพภาคที่ 4 ได้กำชับเน้นย้ำการปฏิบัติของเจ้าหน้าที่ให้ใช้ความระมัดระวัง และพยายามที่จะบังคับใช้กฎหมาย เพื่อนำคนผิดมาลงโทษ แต่การปฏิบัติที่ผ่านมา เจ้าหน้าที่ปฏิบัติด้วยความอยากลำบาก เนื่องจากพื้นที่ที่คนร้ายหลบซ่อนตัวเป็นป่าละเมาะและทุ่งนาบริเวณกว้าง วันแรกและวันที่สองก็ได้มีการเจรจาโดยการนำผู้นำศาสนา ผู้นำท้องถิ่นมาเกลี้ยกล่อมหลายรอบ แต่คนร้ายใช้ความรุนแรงในการตอบโต้จนนำไปสู่การวิสามัญข่าวแนะนำ      โฆษก กอ.รมน.ภาค 4 กล่าวต่อว่า ล่าสุดจากการตรวจสอบพบว่าคนร้ายเสียชีวิตทั้งหมด 7 คนและตรวจยึดอาวุธได้ จำนวน 9 กระบอก ในจำนวนนี้เป็นอาวุธสงคราม 5 กระบอก ปืนพก จำนวน 4 กระบอก ในนามของ กอ.รมน.ภาค 4 ส่วนหน้าขอแสดงความเสียใจต่อครอบครัวและญาติของผู้เสียชีวิตทั้ง 7 ราย ซึ่งเป็นการเสียชีวิตที่เจ้าหน้าที่ไม่อยากให้เกิด เจ้าหน้าที่พยายามใช้ขั้นตอนจากเบาไปหาหนัก แต่คนร้ายเลือกที่จะใช้ความรุนแรงตอบโต้ โดยทางแม่ทัพขอบคุณและชื่นชมเจ้าหน้าที่ทุกฝ่ายในการปฏิบัติครั้งนี้ โดยเฉพาะทหารที่ได้รับบาดเจ็บทั้ง 3 นาย พลตรีปราโมทย์ กล่าวอีกว่า จากการตรวจฐานปฏิบัติการของคนร้ายที่ยึดมาได้ตั้งแต่วันแรกนั้น น่าจะใช้มาแล้วไม่น้อยกว่า 6 เดือน คาดว่าคนร้ายกลุ่มนี้น่าจะวางแผนเตรียมการก่อเหตุขนาดใหญ่ ตามที่เคยแจ้งเตือนมาก่อนหน้านี้ เราได้ประสานไปยังหน่วยงานที่เกี่ยวข้องเข้ามาชันสูตรพลิกศพเบื้องต้น และจะนำศพที่พบทั้งหมดไปชันสูตรอย่างละเอียดที่โรงพยาบาลต่อไป ก่อนส่งศพให้ญาตินำกลับไปประกอบพิธีทางศาสนา ส่วนวัตถุพยานทั้งหมดที่ยึดได้นั้น ทาง ผบช.ภาค 9 ได้สั่งการพนักงานสอบสวนทุกคนเก็บหลักฐานอย่างละเอียด      โฆษก กอ.รมน.ภาค 4 กล่าวด้วยว่า สิ่งที่สำคัญทางแม่ทัพเน้นย้ำให้ใช้งานมวลชนสร้างความเข้าใจต่อประชาชนที่อยู่พื้นที่เกิดเหตุ รวมทั้งสั่งการให้นายอำเภอยะรังเป็นหน่วยหลักในการสำรวจความเสียหายในการปฏิบัติในครั้งนี้ ทางเจ้าหน้าที่พร้อมจะดูแลเยียวยาผู้ได้รับความเสียหายของการปฏิบัติของเจ้าหน้าที่ สุดท้ายการปฏิบัติในครั้งนี้เจ้าหน้าที่ทุกคนใช้ความระมัดระวังกันเต็มที่ แต่คนร้ายเลือกที่จะใช้ความรุนแรงในการตอบโต้จนนำไปสู่การสูญเสีย ทั้งนี้ กอ.รมน.ภาค 4 ส่วนหน้า พร้อมเปิดโอกาสให้คนที่เห็นต่างจากรัฐที่ต้องการยุติความรุนแรงขอให้เข้ามารายงานตัวแสดงตัวต่อเจ้าหน้าที่ รับรองว่าทุกคนจะได้รับความยุติธรรมแน่นอน.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2979]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_text_arr = []\n",
    "# for i in range(len(X_train)):\n",
    "#     print(i)\n",
    "#     clean_text = clean_msg(X_train[i][0])\n",
    "#     temp_arr = []\n",
    "#     temp_arr.append(clean_text)\n",
    "#     clean_text_arr.append(temp_arr)\n",
    "# # print(clean_text_arr)\n",
    "# X_train = np.array(clean_text_arr)\n",
    "# print(X_train)\n",
    "# print(Y_train)\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into train,test,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "X_train, Y_train, X_val, Y_val = iterative_train_test_split(X_train,Y_train,test_size=0.1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = np.array([text for sub in X_train for text in sub]) \n",
    "X_test_new = np.array([text for sub in X_test for text in sub]) \n",
    "X_val_new = np.array([text for sub in X_val for text in sub]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = X_train_new.tolist()\n",
    "X_test_list = X_test_new.tolist()\n",
    "X_val_list = X_val_new.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, CamembertTokenizer, XLMRobertaTokenizer\n",
    "# cstorm125/wangchanberta-base-att-spm-uncased-finetune\n",
    "# airesearch/wangchanberta-base-att-spm-uncased\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(chosen_premodel)\n",
    "\n",
    "def preprocessing_for_bert(data):\n",
    "\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sent in data:\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            #text=text_preprocessing(sent),  \n",
    "            text=sent,\n",
    "            add_special_tokens=True,        \n",
    "            max_length=MAX_LEN,\n",
    "            truncation=True,             \n",
    "            padding='max_length',         \n",
    "            #return_tensors='pt',           \n",
    "            return_attention_mask=True      \n",
    "        )\n",
    "        \n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = np.concatenate([X_train_list, X_test_list, X_val_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "encoded_texts = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  สาวใหญ่ร้องทุกข์ ตร.นครนายก โดนหนุ่มหื่นบุกอนาจารถึงบ้าน ชี้เป็นภัยสังคม สาวใหญ่ ร้อง ตร.นครนายก ตามจับหนุ่มหื่นบุกรุกและอนาจารถึงในรีสอร์ต โชคดีหนีออกมาขอคนช่วยได้ทัน วงจรปิดจับภาพ พบผู้ก่อเหตุมีประวัติถูกจับแล้วประกันตัวออกมา วอน จนท.จัดการเพราะเป็นภัยสังคมเมื่อเวลาประมาณ 15.00 น. ของวันที่ 8 มิถุนายน 2563 ขณะ พ.ต.ต.วีรศักดิ์ ญาณวุฒิโท สว.(สอบสวน) สภ.เมืองนครนายก กำลังปฏิบัติหน้าที่อยู่ได้มีผู้เสียหายเป็นหญิงอายุ 45 ปี เข้าแจ้งความให้ช่วยติดตามผู้ก่อเหตุเป็นชายขี่รถจักรยานยนต์ ยี่ห้อฮอนด้า ซุปเปอร์คลับ สีฟ้า ทะเบียน... สาวใหญ่ ร้อง ตร.นครนายก ตามจับหนุ่มหื่นบุกรุกและอนาจารถึงในรีสอร์ต โชคดีหนีออกมาขอคนช่วยได้ทัน วงจรปิดจับภาพ พบผู้ก่อเหตุมีประวัติถูกจับแล้วประกันตัวออกมา วอน จนท.จัดการเพราะเป็นภัยสังคมเมื่อเวลาประมาณ 15.00 น. ของวันที่ 8 มิถุนายน 2563 ขณะ พ.ต.ต.วีรศักดิ์ ญาณวุฒิโท สว.(สอบสวน) สภ.เมืองนครนายก กำลังปฏิบัติหน้าที่อยู่ได้มีผู้เสียหายเป็นหญิงอายุ 45 ปี เข้าแจ้งความให้ช่วยติดตามผู้ก่อเหตุเป็นชายขี่รถจักรยานยนต์ ยี่ห้อฮอนด้า ซุปเปอร์คลับ สีฟ้า ทะเบียน 1 กค 3422 นครนายก เข้ามาจอดในรีสอร์ตแห่งหนึ่ง หมู่ 3 ต.หินตั้ง อ.เมือง จ.นครนายก ทำทีมาสอบถามราคาที่พัก และขอให้พาเดินไปดูห้องพัก ตนเองเห็นลักษณะท่าทางไม่น่าไว้ใจ เลยพาเดินไปดูห้องที่มีกล้องวงจรปิดติดอยู่ หากมีอะไรเกิดขึ้นจะได้มีหลักฐาน แต่ตนเองไม่ได้เปิดห้องให้เข้าดูเพราะไม่ไว้ใจข่าวแนะนำ      หลังจากนั้นผู้ก่อเหตุได้บอกว่าเดี๋ยวจะไปบอกเพื่อนๆ ก่อนแล้วก็ขี่รถออกไป ไม่นานก็กลับเข้ามาอีกครั้ง ครั้งนี้มานั่งอยู่บริเวณหน้าห้องต้อนรับลูกค้า&nbsp;ตนเริ่มสงสัยเลยไม่เปิดประตูออกไปคุยด้วย แต่แง้มประตูเล็กน้อยเพื่อสนทนา ผู้ก่อเหตุอ้างว่านั่งรอเพื่อนที่กำลังตามมา 3-4 คน และเดินมาหาตนเองที่ประตู บอกขอน้ำกินหน่อยตนเองบอกไม่มี หลังจากนั้นผู้ก่อเหตุได้ผลักตนเองเข้าไปในห้อง ล็อกคอ และพยายามทำมิดีมิร้าย จึงได้ต่อสู้สุดฤทธิ์ เสียงโทรศัพท์ดังขึ้นทำให้ผู้ก่อเหตุชะงัก จังหวะนั้นตนเองได้ถีบไปหนึ่งที จนสามารถดิ้นหลุดเอาตัวรอดออกมาได้ และวิ่งหนีไปขอความช่วยเหลือ&nbsp;ส่วนผู้ก่อเหตุตกใจได้วิ่งถือรองเท้าแตะและขี่รถหลบหนีไปทางเขื่อนขุนด่านปราการชล       จากการตรวจดูกล้องวงจรปิดจับภาพได้ชัดเจน จึงนำภาพไปให้หญิงสาวที่กำลังพับผ้าอยู่ในบ้านพักของตนเอง เมื่ออาทิตย์ก่อนที่เคยถูกกระทำในลักษณะเดียวกันบอกว่าเป็นคนๆ เดียวกัน ชื่อนายตี๋ โดยถูกจับแล้วประกันตัวออกมา จึงอยากให้เจ้าหน้าที่ตำรวจรีบจับตัวมาให้โดยเร็ว เพราะทราบว่า นายตี๋ เวลาเสพยาเสพติดแล้วมักจะควบคุมอารมณ์ของตัวเองไม่ได้ ถือว่าเป็นภัยต่อสังคม เกรงว่าจะไปก่อเหตุซ้ำอีก.\n",
      "\n",
      "\n",
      "Tokenized:  ['▁สาว', 'ใหญ่', 'ร้อง', 'ทุกข์', '▁ตร', '.', 'นคร', 'นาย', 'ก', '▁', 'โดน', 'หนุ่ม', 'ห', 'ื', '่น', 'บุก', 'อ', 'นา', 'จา', 'ร', 'ถึงบ้าน', '▁', 'ชี้', 'เป็น', 'ภัย', 'สังคม', '▁สาว', 'ใหญ่', '▁', 'ร้อง', '▁ตร', '.', 'นคร', 'นาย', 'ก', '▁ตาม', 'จับ', 'หนุ่ม', 'ห', 'ื', '่น', 'บุก', 'รุก', 'และ', 'อ', 'นา', 'จา', 'ร', 'ถึง', 'ใน', 'รี', 'ส', 'อร์', 'ต', '▁', 'โชคดี', 'หนี', 'ออกมา', 'ขอ', 'คน', 'ช่วย', 'ได้', 'ทัน', '▁', 'วง', 'จร', 'ปิด', 'จับ', 'ภาพ', '▁', 'พบ', 'ผู้', 'ก่อ', 'เหตุ', 'มี', 'ประวัติ', 'ถูก', 'จับ', 'แล้ว', 'ประกัน', 'ตัว', 'ออกมา', '▁ว', 'อน', '▁จน', 'ท', '.', 'จัดการ', 'เพราะ', 'เป็น', 'ภัย', 'สังคม', 'เมื่อ', 'เวลา', 'ประมาณ', '▁15.00', '▁น', '.', '▁ของ', 'วันที่', '▁8', '▁มิถุนายน', '▁25', '63', '▁', 'ขณะ', '▁พ', '.', 'ต', '.', 'ต', '.', 'วี', 'ร', 'ศักดิ์', '▁', 'ญาณ', 'วุฒิ', 'โท', '▁', 'สว', '.', '(', 'สอบสวน', ')', '▁ส', 'ภ', '.', 'เมือง', 'นคร', 'นาย', 'ก', '▁กําลัง', 'ปฏิบัติ', 'หน้าที่', 'อยู่', 'ได้', 'มีผู้', 'เสียหาย', 'เป็น', 'หญิง', 'อายุ', '▁45', '▁ปี', '▁เข้า', 'แจ้ง', 'ความ', 'ให้', 'ช่วย', 'ติดตาม', 'ผู้', 'ก่อ', 'เหตุ', 'เป็น', 'ชาย', 'ขี่', 'รถ', 'จักรยาน', 'ยนต์', '▁', 'ยี่ห้อ', 'ฮ', 'อน', 'ด้า', '▁', 'ซุ', 'ป', 'เปอร์', 'คลับ', '▁', 'สีฟ้า', '▁', 'ทะเบียน', '...', '▁สาว', 'ใหญ่', '▁', 'ร้อง', '▁ตร', '.', 'นคร', 'นาย', 'ก', '▁ตาม', 'จับ', 'หนุ่ม', 'ห', 'ื', '่น', 'บุก', 'รุก', 'และ', 'อ', 'นา', 'จา', 'ร', 'ถึง', 'ใน', 'รี', 'ส', 'อร์', 'ต', '▁', 'โชคดี', 'หนี', 'ออกมา', 'ขอ', 'คน', 'ช่วย', 'ได้', 'ทัน', '▁', 'วง', 'จร', 'ปิด', 'จับ', 'ภาพ', '▁', 'พบ', 'ผู้', 'ก่อ', 'เหตุ', 'มี', 'ประวัติ', 'ถูก', 'จับ', 'แล้ว', 'ประกัน', 'ตัว', 'ออกมา', '▁ว', 'อน', '▁จน', 'ท', '.', 'จัดการ', 'เพราะ', 'เป็น', 'ภัย', 'สังคม', 'เมื่อ', 'เวลา', 'ประมาณ', '▁15.00', '▁น', '.', '▁ของ', 'วันที่', '▁8', '▁มิถุนายน', '▁25', '63', '▁', 'ขณะ', '▁พ', '.', 'ต', '.', 'ต', '.', 'วี', 'ร', 'ศักดิ์', '▁', 'ญาณ', 'วุฒิ', 'โท', '▁', 'สว', '.', '(', 'สอบสวน', ')', '▁ส', 'ภ', '.', 'เมือง', 'นคร', 'นาย', 'ก', '▁กําลัง', 'ปฏิบัติ', 'หน้าที่', 'อยู่', 'ได้', 'มีผู้', 'เสียหาย', 'เป็น', 'หญิง', 'อายุ', '▁45', '▁ปี', '▁เข้า', 'แจ้ง', 'ความ', 'ให้', 'ช่วย', 'ติดตาม', 'ผู้', 'ก่อ', 'เหตุ', 'เป็น', 'ชาย', 'ขี่', 'รถ', 'จักรยาน', 'ยนต์', '▁', 'ยี่ห้อ', 'ฮ', 'อน', 'ด้า', '▁', 'ซุ', 'ป', 'เปอร์', 'คลับ', '▁', 'สีฟ้า', '▁', 'ทะเบียน', '▁1', '▁ก', 'ค', '▁34', '22', '▁', 'นคร', 'นาย', 'ก', '▁', 'เข้ามา', 'จอด', 'ใน', 'รี', 'ส', 'อร์', 'ต', 'แห่ง', 'หนึ่ง', '▁', 'หมู่', '▁3', '▁ต', '.', 'หิน', 'ตั้ง', '▁อ', '.', 'เมือง', '▁จ', '.', 'นคร', 'นาย', 'ก', '▁ทํา', 'ที', 'มา', 'สอบถาม', 'ราคา', 'ที่พัก', '▁และ', 'ขอให้', 'พา', 'เดิน', 'ไปดู', 'ห้องพัก', '▁', 'ตนเอง', 'เห็น', 'ลักษณะ', 'ท่า', 'ทาง', 'ไม่', 'น่า', 'ไว้', 'ใจ', '▁เลย', 'พา', 'เดิน', 'ไปดู', 'ห้อง', 'ที่มี', 'กล้องวงจรปิด', 'ติด', 'อยู่', '▁หาก', 'มีอะไร', 'เกิดขึ้น', 'จะได้', 'มี', 'หลักฐาน', '▁แต่', 'ตนเอง', 'ไม่ได้', 'เปิด', 'ห้อง', 'ให้', 'เข้า', 'ดู', 'เพราะ', 'ไม่', 'ไว้', 'ใจ', 'ข่าว', 'แนะนํา', '▁หลังจาก', 'นั้น', 'ผู้', 'ก่อ', 'เหตุ', 'ได้', 'บอกว่า', 'เดี๋ยว', 'จะไป', 'บอก', 'เพื่อนๆ', '▁ก่อน', 'แล้วก็', 'ขี่', 'รถ', 'ออกไป', '▁ไม่', 'นาน', 'ก็', 'กลับ', 'เข้ามา', 'อีกครั้ง', '▁', 'ครั้งนี้', 'มา', 'นั่ง', 'อยู่', 'บริเวณ', 'หน้า', 'ห้อง', 'ต้อนรับ', 'ลูกค้า', '&', 'nbsp', ';', 'ตน', 'เริ่ม', 'สงสัย', 'เลย', 'ไม่', 'เปิด', 'ประตู', 'ออกไป', 'คุย', 'ด้วย', '▁แต่', 'แ', 'ง', '้ม', 'ประตู', 'เล็กน้อย', 'เพื่อ', 'สนทนา', '▁ผู้', 'ก่อ', 'เหตุ', 'อ้าง', 'ว่า', 'นั่ง', 'รอ', 'เพื่อน', 'ที่กําลัง', 'ตาม', 'มา', '▁3-4', '▁คน', '▁และ', 'เดิน', 'มา', 'หา', 'ตนเอง', 'ที่', 'ประตู', '▁', 'บอก', 'ขอ', 'น้ํา', 'กิน', 'หน่อย', 'ตนเอง', 'บอก', 'ไม่มี', '▁หลังจาก', 'นั้น', 'ผู้', 'ก่อ', 'เหตุ', 'ได้ผล', 'ัก', 'ตนเอง', 'เข้าไป', 'ในห้อง', '▁', 'ล็อก', 'คอ', '▁และ', 'พยายาม', 'ทํา', 'มิ', 'ดี', 'มิ', 'ร้าย', '▁', 'จึงได้', 'ต่อสู้', 'สุด', 'ฤทธิ์', '▁', 'เสียง', 'โทรศัพท์', 'ดัง', 'ขึ้น', 'ทําให้', 'ผู้', 'ก่อ', 'เหตุ', 'ช', 'ะ', 'ง', 'ัก', '▁', 'จังหวะ', 'นั้น', 'ตนเอง', 'ได้', 'ถ', 'ี', 'บ', 'ไป', 'หนึ่ง', 'ที', '▁จน', 'สามารถ', 'ด', 'ิ้น', 'หลุด', 'เอา', 'ตัว', 'รอด', 'ออกมา', 'ได้', '▁และ', 'วิ่ง', 'หนี', 'ไป', 'ขอ', 'ความช่วยเหลือ', '&', 'nbsp', ';', 'ส่วน', 'ผู้', 'ก่อ', 'เหตุ', 'ตก', 'ใจ', 'ได้', 'วิ่ง', 'ถือ', 'รองเท้า', 'แตะ', 'และ', 'ขี่', 'รถ', 'ห', 'ลบ', 'หนี', 'ไป', 'ทาง', 'เขื่อน', 'ขุน', 'ด่าน', 'ปรา', 'การ', 'ช', 'ล', '▁จาก', 'การตรวจ', 'ดู', 'กล้องวงจรปิด', 'จับ', 'ภาพ', 'ได้', 'ชัดเจน', '▁จึง', 'นํา', 'ภาพ', 'ไป', 'ให้', 'หญิง', 'สาว', 'ที่กําลัง', 'พับ', 'ผ้า', 'อยู่ใน', 'บ้าน', 'พัก', 'ของ', 'ตนเอง', '▁เมื่อ', 'อาทิตย์', 'ก่อน', 'ที่เคย', 'ถูก', 'กระทํา', 'ใน', 'ลักษณะ', 'เดียวกัน', 'บอกว่า', 'เป็นคน', 'ๆ', '▁', 'เดียวกัน', '▁ชื่อ', 'นาย', 'ตี', '๋', '▁โดย', 'ถูก', 'จับ', 'แล้ว', 'ประกัน', 'ตัว', 'ออกมา', '▁จึง', 'อยากให้', 'เจ้าหน้าที่', 'ตํารวจ', 'รีบ', 'จับ', 'ตัว', 'มาให้', 'โดย', 'เร็ว', '▁เพราะ', 'ทราบว่า', '▁นาย', 'ตี', '๋', '▁เวลา', 'เส', 'พ', 'ยาเสพติด', 'แล้ว', 'มักจะ', 'ควบคุม', 'อารมณ์', 'ของตัวเอง', 'ไม่ได้', '▁', 'ถือว่าเป็น', 'ภัย', 'ต่อ', 'สังคม', '▁', 'เกร', 'ง', 'ว่าจะ', 'ไป', 'ก่อ', 'เหตุ', 'ซ้ํา', 'อีก', '.']\n",
      "\n",
      "\n",
      "Token IDs:  [0, 47282, 9438, 65916, 171144, 127105, 5, 60066, 22414, 2286, 6, 34265, 42520, 6535, 27021, 42291, 132613, 5407, 8403, 50377, 4041, 204018, 6, 104760, 1805, 73926, 35320, 47282, 9438, 6, 65916, 127105, 5, 60066, 22414, 2286, 46058, 25697, 42520, 6535, 27021, 42291, 132613, 152994, 1213, 5407, 8403, 50377, 4041, 8959, 1201, 16871, 1848, 17807, 3356, 6, 183905, 93042, 25913, 17133, 5683, 21051, 1547, 69617, 6, 15262, 65075, 34031, 25697, 10343, 6, 24006, 6772, 151877, 59091, 2386, 114497, 13590, 25697, 3286, 92711, 4214, 25913, 50721, 43540, 58144, 3380, 5, 88329, 26030, 1805, 73926, 35320, 14153, 14759, 30356, 81575, 10383, 5, 16841, 44442, 382, 129048, 714, 15748, 6, 55542, 11308, 5, 3356, 5, 3356, 5, 28260, 4041, 86440, 6, 227367, 125515, 117757, 6, 92185, 5, 132, 215271, 16, 14990, 31606, 5, 12871, 60066, 22414, 2286, 101806, 64723, 72497, 5803, 1547, 179572, 216008, 1805, 38214, 43516, 2678, 10249, 107218, 33851, 4260, 2035, 21051, 45724, 6772, 151877, 59091, 1805, 22850, 197251, 10599, 154154, 164043, 6, 161516, 37784, 43540, 133143, 6, 86130, 3875, 104928, 166519, 6, 188093, 6, 150088, 27, 47282, 9438, 6, 65916, 127105, 5, 60066, 22414, 2286, 46058, 25697, 42520, 6535, 27021, 42291, 132613, 152994, 1213, 5407, 8403, 50377, 4041, 8959, 1201, 16871, 1848, 17807, 3356, 6, 183905, 93042, 25913, 17133, 5683, 21051, 1547, 69617, 6, 15262, 65075, 34031, 25697, 10343, 6, 24006, 6772, 151877, 59091, 2386, 114497, 13590, 25697, 3286, 92711, 4214, 25913, 50721, 43540, 58144, 3380, 5, 88329, 26030, 1805, 73926, 35320, 14153, 14759, 30356, 81575, 10383, 5, 16841, 44442, 382, 129048, 714, 15748, 6, 55542, 11308, 5, 3356, 5, 3356, 5, 28260, 4041, 86440, 6, 227367, 125515, 117757, 6, 92185, 5, 132, 215271, 16, 14990, 31606, 5, 12871, 60066, 22414, 2286, 101806, 64723, 72497, 5803, 1547, 179572, 216008, 1805, 38214, 43516, 2678, 10249, 107218, 33851, 4260, 2035, 21051, 45724, 6772, 151877, 59091, 1805, 22850, 197251, 10599, 154154, 164043, 6, 161516, 37784, 43540, 133143, 6, 86130, 3875, 104928, 166519, 6, 188093, 6, 150088, 106, 11070, 2543, 4442, 4015, 6, 60066, 22414, 2286, 6, 30393, 111466, 1201, 16871, 1848, 17807, 3356, 15318, 13997, 6, 83044, 138, 28420, 5, 82228, 21509, 9009, 5, 12871, 17671, 5, 60066, 22414, 2286, 34472, 16596, 2131, 73666, 11252, 88563, 1494, 103317, 15141, 21283, 164134, 66316, 6, 94981, 19575, 71503, 36380, 4436, 3379, 17291, 11407, 6299, 97620, 15141, 21283, 164134, 27163, 10818, 239219, 16278, 5803, 29241, 162656, 74140, 37730, 2386, 187586, 4454, 94981, 12707, 16935, 27163, 2035, 9373, 7845, 26030, 3379, 11407, 6299, 23281, 46227, 81263, 5248, 6772, 151877, 59091, 1547, 67415, 130835, 132452, 21766, 132238, 51084, 77375, 197251, 10599, 68795, 13366, 31700, 4365, 28805, 30393, 65880, 6, 108444, 2131, 38048, 5803, 48333, 6596, 27163, 118040, 25771, 1230, 82678, 74, 74173, 33413, 110662, 7353, 3379, 16935, 38196, 68795, 104110, 3918, 4454, 31582, 2824, 64160, 38196, 175942, 7336, 213076, 25948, 151877, 59091, 179425, 2469, 38048, 19868, 25163, 128830, 7552, 2131, 20444, 17249, 1494, 21283, 2131, 7990, 94981, 699, 38196, 6, 21766, 17133, 5763, 19094, 44513, 94981, 21766, 22138, 81263, 5248, 6772, 151877, 59091, 208480, 55599, 94981, 39935, 177637, 2]\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "token_ids = list(preprocessing_for_bert([X_train_new[0]])[0].squeeze().numpy())\n",
    "print('Original: ', X_train_new[0])\n",
    "print('\\n')\n",
    "print('Tokenized: ', tokenizer.tokenize(X_train_new[0]))\n",
    "print('\\n')\n",
    "print('Token IDs: ', token_ids)\n",
    "\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train_new)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "train_labels = torch.FloatTensor(Y_train)\n",
    "val_labels = torch.FloatTensor(Y_val)\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import CamembertConfig\n",
    "\n",
    "\n",
    "def initialize_model(epochs=10):\n",
    "    bert_classifier = XLMRobertaForSequenceClassification.from_pretrained(chosen_premodel,num_labels=8)\n",
    "    bert_classifier = nn.DataParallel(bert_classifier)\n",
    "    bert_classifier.to(device)\n",
    "    \n",
    "    \n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=2e-5,    \n",
    "                      betas=(0.9, 0.98), \n",
    "                      eps=1e-6,\n",
    "                      weight_decay=0.1    \n",
    "                )\n",
    "\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0,\n",
    "                                                num_training_steps=total_steps\n",
    "                )\n",
    "    \n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.BCELoss()\n",
    "m = nn.Sigmoid()\n",
    "training_stats = list()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=10, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            outputs = model(b_input_ids, b_attn_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(m(logits), b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "\n",
    "            training_stats.append(\n",
    "                {\n",
    "                    'Epoch': epoch_i + 1,\n",
    "                    'Training_Loss': avg_train_loss,\n",
    "                    'Valid_Loss': val_loss,\n",
    "                    'Valid_Accuracy': val_accuracy,\n",
    "                    'Time_Elapsed': time_elapsed,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            torch.save(model.state_dict(), f'./Model/XLMR_New_{filename}_epoch{epoch_i+1}.h5')\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, b_attn_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        # Compute loss\n",
    "        #print(logits)\n",
    "        #print(b_labels)\n",
    "        loss = loss_fn(m(logits), b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        # preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        # accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        accuracy = accuracy_thresh(logits.view(-1, 8), b_labels.view(-1, 8))\n",
    "#         accuracy = accuracy_thresh(logits.view(-1, 9), b_labels.view(-1, 9))\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "def accuracy_thresh(y_pred, y_true, thresh:float=0.4, sigmoid:bool=True):\n",
    "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "    if sigmoid: \n",
    "        y_pred = y_pred.sigmoid()\n",
    "    return ((y_pred > thresh) == y_true.byte()).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/crimson/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 34.00 MiB (GPU 0; 23.70 GiB total capacity; 14.23 GiB already allocated; 49.25 MiB free; 14.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_163156/2340336813.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_163156/2929209312.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, epochs, evaluation)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# Perform a forward pass. This will return logits.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_attn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m   1205\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    848\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         )\n\u001b[0;32m--> 850\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    851\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    524\u001b[0m                 )\n\u001b[1;32m    525\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    527\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2436\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2438\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 34.00 MiB (GPU 0; 23.70 GiB total capacity; 14.23 GiB already allocated; 49.25 MiB free; 14.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=4)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=4, evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, b_attn_mask)\n",
    "            logits = outputs.logits\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = all_logits.sigmoid().cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training_Loss</th>\n",
       "      <th>Valid_Loss</th>\n",
       "      <th>Valid_Accuracy</th>\n",
       "      <th>Time_Elapsed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130963</td>\n",
       "      <td>0.124137</td>\n",
       "      <td>0.955926</td>\n",
       "      <td>131.054405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.112421</td>\n",
       "      <td>0.123641</td>\n",
       "      <td>0.951840</td>\n",
       "      <td>131.162455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.171954</td>\n",
       "      <td>0.145563</td>\n",
       "      <td>0.948371</td>\n",
       "      <td>130.548748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.321102</td>\n",
       "      <td>0.209876</td>\n",
       "      <td>0.929737</td>\n",
       "      <td>130.620531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training_Loss  Valid_Loss  Valid_Accuracy  Time_Elapsed\n",
       "Epoch                                                         \n",
       "3           0.130963    0.124137        0.955926    131.054405\n",
       "4           0.112421    0.123641        0.951840    131.162455\n",
       "2           0.171954    0.145563        0.948371    130.548748\n",
       "1           0.321102    0.209876        0.929737    130.620531"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('Epoch')\n",
    "\n",
    "# Display the table.\n",
    "df_stats.sort_values(by=['Valid_Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Run `preprocessing_for_bert` on the test set\n",
    "print('Tokenizing data...')\n",
    "test_inputs, test_masks = preprocessing_for_bert(X_test_new)\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = bert_predict(bert_classifier, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Gambling       0.82      0.92      0.87        25\n",
      "         Murder       0.91      0.94      0.92       256\n",
      "   Sexual Abuse       0.91      0.90      0.90        68\n",
      " Theft/Burglary       0.83      0.75      0.79        77\n",
      "           Drug       0.89      0.89      0.89       104\n",
      "Battery/Assault       0.72      0.71      0.71       189\n",
      "       Accident       0.89      0.79      0.84        72\n",
      "      Non-Crime       0.91      0.77      0.83       140\n",
      "\n",
      "      micro avg       0.86      0.83      0.84       931\n",
      "      macro avg       0.86      0.83      0.84       931\n",
      "   weighted avg       0.86      0.83      0.84       931\n",
      "    samples avg       0.75      0.73      0.73       931\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Gambling', 'Murder', 'Sexual Abuse', 'Theft/Burglary', 'Drug',\n",
       "       'Battery/Assault', 'Accident', 'Non-Crime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# start from 5 since we need to avoid the news_data <Topic,Intro,Desc,All>\n",
    "df_label_columns = df_crime_train.columns[5:]\n",
    "label_names = list(df_label_columns)\n",
    "\n",
    "print(classification_report(Y_test, np.round(probs), target_names=label_names, zero_division=0))\n",
    "df_label_columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
